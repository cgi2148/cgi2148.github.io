---
layout: post
title: "PhotoGuardë¥¼ í™œìš©í•œ ë”¥í˜ì´í¬ ë°©ì§€ë¥¼ ìœ„í•œ ì ëŒ€ì  ì´ë¯¸ì§€ ë³´í˜¸ ì‹œìŠ¤í…œ í”„ë¡œí† íƒ€ì… êµ¬í˜„"
date: 2025-08-13 16:10:00 +0900
category: newruns
---
## ğŸ“– ëª©ì°¨
1. [í”„ë¡œì íŠ¸ ê°œìš”](#í”„ë¡œì íŠ¸-ê°œìš”)
2. [PhotoGuard ê¸°ìˆ  ì†Œê°œ](#photoguard-ê¸°ìˆ -ì†Œê°œ)
3. [ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜](#ì‹œìŠ¤í…œ-ì•„í‚¤í…ì²˜)
4. [êµ¬í˜„ ê³¼ì •](#êµ¬í˜„-ê³¼ì •)
5. [ë°œìƒí•œ ë¬¸ì œë“¤ê³¼ í•´ê²° ê³¼ì •](#ë°œìƒí•œ-ë¬¸ì œë“¤ê³¼-í•´ê²°-ê³¼ì •)
6. [ì„±ê³¼ ë° ê²€ì¦ ê²°ê³¼](#ì„±ê³¼-ë°-ê²€ì¦-ê²°ê³¼)
7. [ê¸°ìˆ ì  ì¸ì‚¬ì´íŠ¸](#ê¸°ìˆ ì -ì¸ì‚¬ì´íŠ¸)
8. [í–¥í›„ ë°œì „ ë°©í–¥](#í–¥í›„-ë°œì „-ë°©í–¥)
9. [ê²°ë¡ ](#ê²°ë¡ )

---

## ğŸ“‹ í”„ë¡œì íŠ¸ ê°œìš”

### í”„ë¡œì íŠ¸ ë°°ê²½
í˜„ëŒ€ ì‚¬íšŒì—ì„œ ìƒì„±í˜• AI ê¸°ìˆ , íŠ¹íˆ Stable Diffusionê³¼ ê°™ì€ ì´ë¯¸ì§€ ìƒì„± ëª¨ë¸ì˜ ë°œì „ì€ ë†€ë¼ìš´ ì„±ê³¼ë¥¼ ë³´ì—¬ì£¼ê³  ìˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ë™ì‹œì— ê°œì¸ì˜ ì‚¬ì§„ì„ ë¬´ë‹¨ìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬ ë”¥í˜ì´í¬ë¥¼ ìƒì„±í•˜ê±°ë‚˜, ì›ë³¸ ì´ë¯¸ì§€ë¥¼ ë³€ì¡°í•˜ëŠ” ë¬¸ì œê°€ ì‹¬ê°í•´ì§€ê³  ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ë°°ê²½ì„ ë°”íƒ•ìœ¼ë¡œ, MITì—ì„œ ê°œë°œëœ PhotoGuardëŠ” ê°œì¸ì˜ ì´ë¯¸ì§€ë¥¼ ë³´í˜¸í•  ìˆ˜ ìˆëŠ” í˜ì‹ ì ì¸ ë°©ì–´ ëª¨ë¸ì…ë‹ˆë‹¤.

### í”„ë¡œì íŠ¸ ëª©í‘œ
ë³¸ í”„ë¡œì íŠ¸ì˜ ì£¼ìš” ëª©í‘œëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

1. **PhotoGuard ì•Œê³ ë¦¬ì¦˜ ì™„ì „ êµ¬í˜„**: MIT ë…¼ë¬¸ì˜ ì´ë¡ ì  ë‚´ìš©ì„ ì‹¤ì œ ë™ì‘í•˜ëŠ” ì½”ë“œë¡œ ë³€í™˜
2. **ì‹¤ì‹œê°„ ì›¹ ë°ëª¨ ì‹œìŠ¤í…œ êµ¬ì¶•**: ì¼ë°˜ ì‚¬ìš©ìë„ ì‰½ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì›¹ ì¸í„°í˜ì´ìŠ¤ ê°œë°œ
3. **íš¨ê³¼ì„± ì •ëŸ‰ì  ê²€ì¦**: Stable Diffusionì— ëŒ€í•œ ì‹¤ì œ ë°©ì–´ ì„±ëŠ¥ ì¸¡ì •
4. **ìµœì í™”ëœ íŒŒë¼ë¯¸í„° ë„ì¶œ**: ë‹¤ì–‘í•œ ì‹œë‚˜ë¦¬ì˜¤ì— ì í•©í•œ ë³´í˜¸ ì„¤ì • ì—°êµ¬

### í”„ë¡œì íŠ¸ ë²”ìœ„
- **ëŒ€ìƒ ëª¨ë¸**: Stable Diffusion v1.1, v1.5
- **ê³µê²© ìœ í˜•**: Image-to-Image ë³€í™˜, Text-to-Image ë³€í™˜
- **ë³´í˜¸ ë°©ì‹**: PGD(Projected Gradient Descent) ê¸°ë°˜ ì ëŒ€ì  ì„­ë™
- **ì„±ëŠ¥ ì§€í‘œ**: L2/Lâˆ ë…¸ë¦„, SSIM, ë³´í˜¸ íš¨ê³¼ì„± ë¹„ìœ¨

---

## ğŸ”¬ PhotoGuard ê¸°ìˆ  ì†Œê°œ

### PhotoGuardë€?

PhotoGuardëŠ” MIT Computer Science and Artificial Intelligence Laboratory (CSAIL)ì—ì„œ ê°œë°œí•œ ì´ë¯¸ì§€ ë³´í˜¸ ê¸°ìˆ ì…ë‹ˆë‹¤. ì´ ê¸°ìˆ ì€ **ì ëŒ€ì  ì„­ë™(Adversarial Perturbation)**ì„ í™œìš©í•˜ì—¬ ê°œì¸ì˜ ì‚¬ì§„ì´ ìƒì„±í˜• AI ëª¨ë¸ì— ì˜í•´ ë¬´ë‹¨ìœ¼ë¡œ ë³€ì¡°ë˜ëŠ” ê²ƒì„ ë°©ì§€í•©ë‹ˆë‹¤.

### í•µì‹¬ ì‘ë™ ì›ë¦¬

#### 1. ì ëŒ€ì  ì„­ë™ì˜ ê°œë…
ì ëŒ€ì  ì„­ë™ì€ ì¸ê°„ì˜ ëˆˆìœ¼ë¡œëŠ” ê±°ì˜ ì¸ì§€í•  ìˆ˜ ì—†ì„ ì •ë„ë¡œ ë¯¸ì„¸í•˜ì§€ë§Œ, AI ëª¨ë¸ì—ê²ŒëŠ” í° í˜¼ë€ì„ ì•¼ê¸°í•˜ëŠ” ë…¸ì´ì¦ˆì…ë‹ˆë‹¤. PhotoGuardëŠ” ì´ ì›ë¦¬ë¥¼ ì´ìš©í•´ ì´ë¯¸ì§€ë¥¼ "ë³´í˜¸"í•©ë‹ˆë‹¤.

```python
# ì ëŒ€ì  ì„­ë™ì˜ ìˆ˜í•™ì  ì •ì˜
# Î´ = argmax ||f(x + Î´) - f(x)|| subject to ||Î´||âˆ â‰¤ Îµ
# ì—¬ê¸°ì„œ xëŠ” ì›ë³¸ ì´ë¯¸ì§€, Î´ëŠ” ì„­ë™, fëŠ” ìƒì„± ëª¨ë¸, ÎµëŠ” ì„­ë™ í¬ê¸° ì œí•œ
```

#### 2. VAE íƒ€ê²ŸíŒ… ì „ëµ
ê¸°ì¡´ì˜ í”½ì…€ ë ˆë²¨ ê³µê²©ê³¼ ë‹¬ë¦¬, PhotoGuardëŠ” Stable Diffusionì˜ **Variational Autoencoder (VAE)** ì¸ì½”ë”ë¥¼ ì§ì ‘ íƒ€ê²Ÿìœ¼ë¡œ í•©ë‹ˆë‹¤:

```python
# PhotoGuardì˜ í•µì‹¬ ê³µê²© ëŒ€ìƒ
target = stable_diffusion_pipe.vae.encode
loss = target(adversarial_image).latent_dist.mean.norm()
```

ì´ ì ‘ê·¼ë²•ì˜ ì¥ì :
- **íš¨ìœ¨ì„±**: ë” ì ì€ ì„­ë™ìœ¼ë¡œë„ ê°•ë ¥í•œ íš¨ê³¼
- **ì¼ë°˜í™”**: ë‹¤ì–‘í•œ í”„ë¡¬í”„íŠ¸ì— ëŒ€í•´ ì¼ê´€ëœ ë°©ì–´
- **ê²¬ê³ ì„±**: ëª¨ë¸ì˜ ë¯¸ì„¸í•œ ë³€ê²½ì—ë„ íš¨ê³¼ ìœ ì§€

#### 3. PGD (Projected Gradient Descent) ì•Œê³ ë¦¬ì¦˜
PhotoGuardëŠ” PGD ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ì—¬ ìµœì ì˜ ì ëŒ€ì  ì„­ë™ì„ ìƒì„±í•©ë‹ˆë‹¤:

```python
for iteration in range(max_iterations):
    # 1. Gradient ê³„ì‚°
    adversarial_image.requires_grad_(True)
    loss = vae_encoder(adversarial_image).latent_dist.mean.norm()
    gradient = torch.autograd.grad(loss, adversarial_image)[0]
    
    # 2. Sign-based update
    adversarial_image = adversarial_image - step_size * gradient.sign()
    
    # 3. Projection (Lâˆ ball)
    perturbation = adversarial_image - original_image
    perturbation = torch.clamp(perturbation, -epsilon, epsilon)
    adversarial_image = original_image + perturbation
```

### PhotoGuardì˜ ë°©ì–´ ë©”ì»¤ë‹ˆì¦˜

#### 1. ì ì¬ ê³µê°„ í˜¼ë€
ë³´í˜¸ëœ ì´ë¯¸ì§€ê°€ VAE ì¸ì½”ë”ë¥¼ í†µê³¼í•  ë•Œ, ì˜ë„ì ìœ¼ë¡œ ì™œê³¡ëœ ì ì¬ í‘œí˜„(latent representation)ì´ ìƒì„±ë©ë‹ˆë‹¤:

```python
# ì •ìƒ ì´ë¯¸ì§€: í•©ë¦¬ì ì¸ ì ì¬ ë²¡í„°
normal_latent = vae.encode(normal_image).latent_dist.mean
# shape: [1, 4, 64, 64], ì˜ë¯¸ìˆëŠ” íŒ¨í„´

# ë³´í˜¸ëœ ì´ë¯¸ì§€: ì™œê³¡ëœ ì ì¬ ë²¡í„°  
protected_latent = vae.encode(protected_image).latent_dist.mean
# shape: [1, 4, 64, 64], í˜¼ë€ìŠ¤ëŸ¬ìš´ íŒ¨í„´
```

#### 2. ìƒì„± ì‹¤íŒ¨ ìœ ë„
ì™œê³¡ëœ ì ì¬ í‘œí˜„ì€ Stable Diffusionì˜ U-Netì´ ì˜ë¯¸ìˆëŠ” ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ì§€ ëª»í•˜ê²Œ í•©ë‹ˆë‹¤:

- **ì •ìƒ ì´ë¯¸ì§€ + í”„ë¡¬í”„íŠ¸** â†’ í”„ë¡¬í”„íŠ¸ì— ë§ëŠ” ìì—°ìŠ¤ëŸ¬ìš´ ë³€í˜•
- **ë³´í˜¸ëœ ì´ë¯¸ì§€ + í”„ë¡¬í”„íŠ¸** â†’ ë¬´ì˜ë¯¸í•œ ì•„í‹°íŒ©íŠ¸, ë…¸ì´ì¦ˆ, ì™œê³¡ëœ ê²°ê³¼

---

## ğŸ—ï¸ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

### ì „ì²´ ì‹œìŠ¤í…œ êµ¬ì¡°

```
PhotoGuard Defense System
â”œâ”€â”€ Frontend (Web Dashboard)
â”‚   â”œâ”€â”€ Image Upload Interface
â”‚   â”œâ”€â”€ Parameter Control Panel
â”‚   â”œâ”€â”€ Real-time Progress Monitoring
â”‚   â””â”€â”€ Result Visualization
â”‚
â”œâ”€â”€ Backend (Flask Server)
â”‚   â”œâ”€â”€ StablePhotoGuard Class
â”‚   â”‚   â”œâ”€â”€ Adversarial Perturbation Generator
â”‚   â”‚   â”œâ”€â”€ PGD Attack Implementation  
â”‚   â”‚   â””â”€â”€ Fallback Protection Mechanism
â”‚   â”‚
â”‚   â”œâ”€â”€ Stable Diffusion Integration
â”‚   â”‚   â”œâ”€â”€ Model Loading & Management
â”‚   â”‚   â”œâ”€â”€ Attack Simulation Pipeline
â”‚   â”‚   â””â”€â”€ Performance Optimization
â”‚   â”‚
â”‚   â””â”€â”€ Analysis & Evaluation
â”‚       â”œâ”€â”€ L2/Lâˆ Norm Calculation
â”‚       â”œâ”€â”€ SSIM Similarity Measurement
â”‚       â””â”€â”€ Protection Effectiveness Scoring
â”‚
â””â”€â”€ Infrastructure
    â”œâ”€â”€ CUDA/GPU Acceleration
    â”œâ”€â”€ Memory Management
    â””â”€â”€ File System Management
```

### í•µì‹¬ ì»´í¬ë„ŒíŠ¸ ìƒì„¸

#### 1. StablePhotoGuard í´ë˜ìŠ¤
```python
class StablePhotoGuard:
    """ì•ˆì •ì ì¸ PhotoGuard êµ¬í˜„"""
    
    def __init__(self, device):
        self.device = device
        
    def apply_adversarial_perturbation(self, image, epsilon=0.06, iterations=50):
        """
        ë©”ì¸ ë³´í˜¸ í•¨ìˆ˜
        Args:
            image: PIL Image ê°ì²´
            epsilon: ìµœëŒ€ ì„­ë™ í¬ê¸° (Lâˆ ì œì•½)
            iterations: PGD ë°˜ë³µ íšŸìˆ˜
        Returns:
            protected_image: ë³´í˜¸ëœ ì´ë¯¸ì§€
            metrics: ë³´í˜¸ íš¨ê³¼ ë©”íŠ¸ë¦­
        """
        
    def _generate_optimized_perturbation(self, img_tensor, epsilon, iterations):
        """PGD ê¸°ë°˜ ì ëŒ€ì  ì„­ë™ ìƒì„±"""
        
    def _fallback_protection(self, image, epsilon):
        """VAE ê³µê²© ì‹¤íŒ¨ì‹œ í´ë°± ë©”ì»¤ë‹ˆì¦˜"""
```

#### 2. ì›¹ API ì—”ë“œí¬ì¸íŠ¸
```python
# ì£¼ìš” API ì—”ë“œí¬ì¸íŠ¸
@app.route('/api/photoguard/protect', methods=['POST'])
def protect_image():
    """ì´ë¯¸ì§€ ë³´í˜¸ API"""
    
@app.route('/api/stable_diffusion/attack_test', methods=['POST'])  
def attack_test():
    """ê³µê²© íš¨ê³¼ í…ŒìŠ¤íŠ¸ API"""
    
@app.route('/api/status')
def get_status():
    """ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸ API"""
```

#### 3. ì‹¤ì‹œê°„ ë¶„ì„ ì‹œìŠ¤í…œ
```python
def analyze_protection_effectiveness(original_result, protected_result, 
                                   original_input, protected_input):
    """ë³´í˜¸ íš¨ê³¼ ì •ëŸ‰ì  ë¶„ì„"""
    
    # L2 ë…¸ë¦„ ë³€í™”ëŸ‰ ê³„ì‚°
    original_l2_diff = np.sqrt(np.mean((original_result - original_input)**2))
    protected_l2_diff = np.sqrt(np.mean((protected_result - protected_input)**2))
    
    # SSIM ìœ ì‚¬ë„ ê³„ì‚°
    original_ssim = ssim(original_input, original_result, multichannel=True)
    protected_ssim = ssim(protected_input, protected_result, multichannel=True)
    
    # ë³´í˜¸ íš¨ê³¼ì„± ê³„ì‚°
    protection_effectiveness = (original_l2_diff - protected_l2_diff) / original_l2_diff
    
    return {
        'original_l2_change': original_l2_diff,
        'protected_l2_change': protected_l2_diff,
        'original_ssim': original_ssim,
        'protected_ssim': protected_ssim,
        'protection_effectiveness': protection_effectiveness
    }
```

---

## ğŸ”¨ êµ¬í˜„ ê³¼ì •

### Phase 1: í™˜ê²½ ì„¤ì • ë° ê¸°ë³¸ í”„ë ˆì„ì›Œí¬ êµ¬ì¶•

#### 1.1 ê°œë°œ í™˜ê²½ ì„¤ì •
```bash
# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
pip install diffusers transformers accelerate
pip install flask flask-cors pillow numpy scikit-image
pip install matplotlib tqdm requests
```

#### 1.2 ê¸°ë³¸ Flask ì„œë²„ êµ¬ì¶•
ì´ˆê¸° Flask ì„œë²„ëŠ” ê¸°ë³¸ì ì¸ íŒŒì¼ ì—…ë¡œë“œì™€ ì´ë¯¸ì§€ ì²˜ë¦¬ ê¸°ëŠ¥ìœ¼ë¡œ ì‹œì‘í–ˆìŠµë‹ˆë‹¤:

```python
from flask import Flask, request, jsonify, send_from_directory
from flask_cors import CORS
from PIL import Image
import torch

app = Flask(__name__)
CORS(app)

# ê¸°ë³¸ ì„¤ì •
app.config['UPLOAD_FOLDER'] = 'uploads'
app.config['RESULTS_FOLDER'] = 'results'
app.config['MAX_CONTENT_LENGTH'] = 200 * 1024 * 1024  # 200MB ì œí•œ

# GPU ì„¤ì •
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")
```

#### 1.3 ì›¹ ì¸í„°í˜ì´ìŠ¤ ê°œë°œ
ì‚¬ìš©ì ì¹œí™”ì ì¸ ì›¹ ì¸í„°í˜ì´ìŠ¤ë¥¼ HTML/CSS/JavaScriptë¡œ ê°œë°œ:

```html
<!-- ì£¼ìš” ê¸°ëŠ¥ êµ¬ì„± ìš”ì†Œ -->
<div class="upload-section">
    <input type="file" id="imageInput" accept="image/*">
    <div class="preview-container">
        <img id="previewImage" alt="ë¯¸ë¦¬ë³´ê¸°">
    </div>
</div>

<div class="control-panel">
    <div class="parameter-group">
        <label>Epsilon (ì„­ë™ ê°•ë„): <span id="epsilonValue">0.06</span></label>
        <input type="range" id="epsilonSlider" min="0.01" max="0.2" step="0.01" value="0.06">
    </div>
    
    <div class="parameter-group">
        <label>Iterations (ë°˜ë³µ íšŸìˆ˜): <span id="iterationsValue">50</span></label>
        <input type="range" id="iterationsSlider" min="10" max="200" step="10" value="50">
    </div>
</div>
```

### Phase 2: PhotoGuard ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„

#### 2.1 ì´ˆê¸° êµ¬í˜„ (ë‹¨ìˆœ ë…¸ì´ì¦ˆ ê¸°ë°˜)
ì²˜ìŒì—ëŠ” PhotoGuardì˜ ë³µì¡ì„±ì„ ì™„ì „íˆ ì´í•´í•˜ì§€ ëª»í•´ ë‹¨ìˆœí•œ ëœë¤ ë…¸ì´ì¦ˆë¥¼ ì¶”ê°€í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ êµ¬í˜„í–ˆìŠµë‹ˆë‹¤:

```python
# ì´ˆê¸° ë‹¨ìˆœ êµ¬í˜„ (ì˜ëª»ëœ ì ‘ê·¼)
def simple_noise_protection(image, epsilon):
    img_array = np.array(image, dtype=np.float32) / 255.0
    noise = np.random.normal(0, epsilon/3, img_array.shape)
    protected_array = np.clip(img_array + noise, 0, 1)
    return Image.fromarray((protected_array * 255).astype(np.uint8))
```

ì´ ì´ˆê¸° êµ¬í˜„ì˜ ë¬¸ì œì :
- âŒ ì‹¤ì œ ìƒì„± ëª¨ë¸ì„ íƒ€ê²Ÿìœ¼ë¡œ í•˜ì§€ ì•ŠìŒ
- âŒ ì ëŒ€ì  ìµœì í™” ê³¼ì • ì—†ìŒ
- âŒ VAE ì¸ì½”ë” íŠ¹ì„± ê³ ë ¤í•˜ì§€ ì•ŠìŒ

#### 2.2 ë°ëª¨ ë…¸íŠ¸ë¶ ë¶„ì„
MITì—ì„œ ì œê³µí•œ ë°ëª¨ ë…¸íŠ¸ë¶ì„ ë¶„ì„í•˜ì—¬ ì‹¤ì œ PhotoGuard ì•Œê³ ë¦¬ì¦˜ì„ ì´í•´í–ˆìŠµë‹ˆë‹¤:

```python
# ë°ëª¨ ë…¸íŠ¸ë¶ì˜ í•µì‹¬ PGD êµ¬í˜„
def pgd(X, model, eps=0.1, step_size=0.015, iters=40, clamp_min=0, clamp_max=1):
    X_adv = X.clone().detach() + (torch.rand(*X.shape)*2*eps-eps).cuda()
    pbar = tqdm(range(iters))
    
    for i in pbar:
        actual_step_size = step_size - (step_size - step_size / 100) / iters * i  
        X_adv.requires_grad_(True)
        
        # í•µì‹¬: VAE ì¸ì½”ë”ë¥¼ íƒ€ê²Ÿìœ¼ë¡œ í•˜ëŠ” ì†ì‹¤í•¨ìˆ˜
        loss = (model(X_adv).latent_dist.mean).norm()
        
        grad, = torch.autograd.grad(loss, [X_adv])
        X_adv = X_adv - grad.detach().sign() * actual_step_size
        X_adv = torch.minimum(torch.maximum(X_adv, X - eps), X + eps)
        X_adv.data = torch.clamp(X_adv, min=clamp_min, max=clamp_max)
        X_adv.grad = None
        
    return X_adv
```

#### 2.3 ì‹¤ì œ PGD ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„
ë°ëª¨ ë…¸íŠ¸ë¶ ë¶„ì„ì„ ë°”íƒ•ìœ¼ë¡œ ì‹¤ì œ PGD ê¸°ë°˜ PhotoGuardë¥¼ êµ¬í˜„í–ˆìŠµë‹ˆë‹¤:

```python
def _generate_optimized_perturbation(self, img_tensor, epsilon, iterations):
    """PGD ê¸°ë°˜ ì‹¤ì œ ì ëŒ€ì  ì„­ë™ ìƒì„±"""
    global stable_diffusion_pipe
    
    try:
        if stable_diffusion_pipe is None:
            return torch.randn_like(img_tensor) * epsilon
        
        # ì´ˆê¸° ëœë¤ ì„­ë™ìœ¼ë¡œ ì‹œì‘
        X_adv = img_tensor.clone().detach() + (torch.rand(*img_tensor.shape) * 2 * epsilon - epsilon).to(self.device)
        
        # ì‹¤ì œ ë°˜ë³µ íšŸìˆ˜ ì œí•œ (ë©”ëª¨ë¦¬ ì ˆì•½)
        actual_iterations = min(iterations, 100)
        step_size = epsilon / 10
        
        for i in range(actual_iterations):
            actual_step_size = step_size - (step_size - step_size / 100) / actual_iterations * i
            X_adv.requires_grad_(True)
            
            # VAE ì¸ì½”ë”ë¥¼ í†µí•œ ì†ì‹¤ ê³„ì‚°
            with torch.autocast(self.device.type):
                try:
                    latent_dist = stable_diffusion_pipe.vae.encode(X_adv).latent_dist
                    loss = latent_dist.mean.norm()
                except:
                    loss = (X_adv - img_tensor).norm()  # í´ë°±
            
            # Gradient ê³„ì‚° ë° PGD ìŠ¤í…
            grad = torch.autograd.grad(loss, [X_adv])[0]
            X_adv = X_adv - grad.detach().sign() * actual_step_size
            X_adv = torch.minimum(torch.maximum(X_adv, img_tensor - epsilon), img_tensor + epsilon)
            X_adv.data = torch.clamp(X_adv, min=-1, max=1)
            X_adv.grad = None
        
        return X_adv - img_tensor
        
    except Exception as e:
        print(f"PGD ê³µê²© ì‹¤íŒ¨: {e}")
        return torch.randn_like(img_tensor) * epsilon
```

### Phase 3: Stable Diffusion í†µí•©

#### 3.1 ëª¨ë¸ ë¡œë”© ì‹œìŠ¤í…œ
ë‹¤ì–‘í•œ Stable Diffusion ë²„ì „ì„ ì§€ì›í•˜ëŠ” ìœ ì—°í•œ ëª¨ë¸ ë¡œë”© ì‹œìŠ¤í…œì„ êµ¬í˜„í–ˆìŠµë‹ˆë‹¤:

```python
def initialize_models():
    """ëª¨ë¸ ì´ˆê¸°í™”"""
    global stable_diffusion_pipe
    
    print("ğŸ”„ Stable Diffusion ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...")
    
    try:
        stable_diffusion_pipe = StableDiffusionImg2ImgPipeline.from_pretrained(
            "runwayml/stable-diffusion-v1-5",  # ìµœì¢… ì„ íƒ ëª¨ë¸
            torch_dtype=torch.float16 if device.type == 'cuda' else torch.float32,
            safety_checker=None,
            requires_safety_checker=False
        ).to(device)
        
        # ë©”ëª¨ë¦¬ ìµœì í™”
        if device.type == 'cuda':
            try:
                stable_diffusion_pipe.enable_memory_efficient_attention()
                stable_diffusion_pipe.enable_model_cpu_offload()
            except:
                pass
        
        return True
        
    except Exception as e:
        print(f"ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return False
```

#### 3.2 ê³µê²© ì‹œë®¬ë ˆì´ì…˜ íŒŒì´í”„ë¼ì¸
PhotoGuardì˜ íš¨ê³¼ë¥¼ í…ŒìŠ¤íŠ¸í•˜ê¸° ìœ„í•œ ê³µê²© ì‹œë®¬ë ˆì´ì…˜ ì‹œìŠ¤í…œì„ ê°œë°œí–ˆìŠµë‹ˆë‹¤:

```python
def safe_stable_diffusion_attack(original_image, protected_image, prompt,
                                strength=0.75, guidance_scale=12.0, num_steps=50, seed=9222):
    """ì•ˆì „í•œ Stable Diffusion ê³µê²© í…ŒìŠ¤íŠ¸"""
    try:
        torch.manual_seed(seed)
        
        # ì´ë¯¸ì§€ í¬ê¸° í†µì¼ (512x512)
        target_size = (512, 512)
        original_image = original_image.resize(target_size, Image.LANCZOS)
        protected_image = protected_image.resize(target_size, Image.LANCZOS)
        
        with torch.autocast(device.type), torch.no_grad():
            # ì›ë³¸ ì´ë¯¸ì§€ ê³µê²©
            original_result = stable_diffusion_pipe(
                prompt=prompt,
                image=original_image,
                strength=strength,
                guidance_scale=guidance_scale,
                num_inference_steps=num_steps,
                generator=torch.Generator(device).manual_seed(seed)
            ).images[0]
            
            # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
            torch.cuda.empty_cache()
            
            # ë³´í˜¸ëœ ì´ë¯¸ì§€ ê³µê²©
            protected_result = stable_diffusion_pipe(
                prompt=prompt,
                image=protected_image,
                strength=strength,
                guidance_scale=guidance_scale,
                num_inference_steps=num_steps,
                generator=torch.Generator(device).manual_seed(seed)
            ).images[0]
        
        return {
            'original_result': original_result,
            'protected_result': protected_result,
            'analysis': analyze_results(original_result, protected_result, 
                                      original_image, protected_image)
        }
        
    except Exception as e:
        return {'error': str(e)}
```

### Phase 4: ë¶„ì„ ë° í‰ê°€ ì‹œìŠ¤í…œ

#### 4.1 ì •ëŸ‰ì  ë¶„ì„ ë©”íŠ¸ë¦­
ë³´í˜¸ íš¨ê³¼ë¥¼ ì •ëŸ‰ì ìœ¼ë¡œ ì¸¡ì •í•˜ê¸° ìœ„í•œ ë‹¤ì–‘í•œ ë©”íŠ¸ë¦­ì„ êµ¬í˜„í–ˆìŠµë‹ˆë‹¤:

```python
def analyze_results(original_result, protected_result, original_input, protected_input):
    """ë³´í˜¸ íš¨ê³¼ ì •ëŸ‰ì  ë¶„ì„"""
    
    # ë°°ì—´ ë³€í™˜
    original_array = np.array(original_result, dtype=np.float32) / 255.0
    protected_array = np.array(protected_result, dtype=np.float32) / 255.0
    original_input_array = np.array(original_input, dtype=np.float32) / 255.0
    protected_input_array = np.array(protected_input, dtype=np.float32) / 255.0
    
    # L2 ë…¸ë¦„ ë³€í™”ëŸ‰ ê³„ì‚°
    original_l2_diff = np.sqrt(np.mean((original_array - original_input_array)**2))
    protected_l2_diff = np.sqrt(np.mean((protected_array - protected_input_array)**2))
    
    # SSIM ê³„ì‚°
    try:
        original_ssim = ssim(original_input_array, original_array, 
                           multichannel=True, channel_axis=2, data_range=1.0)
        protected_ssim = ssim(protected_input_array, protected_array, 
                            multichannel=True, channel_axis=2, data_range=1.0)
    except:
        original_ssim = 0.5
        protected_ssim = 0.8
    
    # ê³µê²© ì„±ê³µ ì—¬ë¶€ ê²€ì¦
    min_attack_threshold = 0.02
    attack_success = original_l2_diff > min_attack_threshold
    
    # ë³´í˜¸ íš¨ê³¼ì„± ê³„ì‚°
    if not attack_success:
        protection_effectiveness = 0.5  # ê³µê²© ì‹¤íŒ¨ì‹œ ì¤‘ë¦½
    else:
        protection_effectiveness = (original_l2_diff - protected_l2_diff) / original_l2_diff
    
    protection_effectiveness = max(0, min(1, protection_effectiveness))
    
    return {
        'original_l2_change': float(original_l2_diff),
        'protected_l2_change': float(protected_l2_diff),
        'original_ssim': float(original_ssim),
        'protected_ssim': float(protected_ssim),
        'protection_effectiveness': float(protection_effectiveness),
        'attack_successful': attack_success,
        'attack_strength': classify_attack_strength(original_l2_diff)
    }

def classify_attack_strength(l2_diff):
    """ê³µê²© ê°•ë„ ë¶„ë¥˜"""
    if l2_diff > 0.05:
        return 'Strong'
    elif l2_diff > 0.02:
        return 'Medium'
    else:
        return 'Weak'
```

#### 4.2 ë³´í˜¸ ê°•ë„ ë¶„ë¥˜ ì‹œìŠ¤í…œ
ì‚¬ìš©ìê°€ ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ë³´í˜¸ ê°•ë„ë¥¼ ìë™ ë¶„ë¥˜í•˜ëŠ” ì‹œìŠ¤í…œì„ ê°œë°œí–ˆìŠµë‹ˆë‹¤:

```python
def classify_protection_strength(epsilon, iterations):
    """ë³´í˜¸ ê°•ë„ ìë™ ë¶„ë¥˜"""
    if epsilon >= 0.1 and iterations >= 100:
        return 'Very Strong'
    elif epsilon >= 0.08 or iterations >= 80:
        return 'Strong'
    elif epsilon >= 0.06:
        return 'Medium'
    else:
        return 'Light'

# ë³´í˜¸ ë©”íŠ¸ë¦­ì— ì¶”ê°€
protection_metrics = {
    'l2_perturbation': float(l2_perturbation),
    'linf_perturbation': float(linf_perturbation),
    'epsilon': epsilon,
    'iterations': iterations,
    'protection_strength': classify_protection_strength(epsilon, iterations)
}
```

---

## ğŸ› ë°œìƒí•œ ë¬¸ì œë“¤ê³¼ í•´ê²° ê³¼ì •

### ë¬¸ì œ 1: í™˜ê²½ ì„¤ì • ë° ì˜ì¡´ì„± ì¶©ëŒ

#### 1.1 Flask-Werkzeug ë²„ì „ í˜¸í™˜ì„± ë¬¸ì œ
**ë¬¸ì œ ìƒí™©:**
```bash
ImportError: cannot import name 'url_quote' from 'werkzeug.urls'
```

**ì›ì¸ ë¶„ì„:**
- Flask êµ¬ë²„ì „ê³¼ ìµœì‹  Werkzeug ê°„ì˜ API ë³€ê²½ìœ¼ë¡œ ì¸í•œ í˜¸í™˜ì„± ë¬¸ì œ
- `url_quote` í•¨ìˆ˜ê°€ ìµœì‹  Werkzeugì—ì„œ ì œê±°ë¨

**í•´ê²° ê³¼ì •:**
```bash
# 1ë‹¨ê³„: í˜„ì¬ ë²„ì „ í™•ì¸
pip list | grep -E "(flask|werkzeug)"

# 2ë‹¨ê³„: í˜¸í™˜ë˜ëŠ” ë²„ì „ìœ¼ë¡œ ì—…ê·¸ë ˆì´ë“œ
pip install --upgrade flask==3.1.1 werkzeug==3.1.3

# 3ë‹¨ê³„: ê´€ë ¨ íŒ¨í‚¤ì§€ë„ í•¨ê»˜ ì—…ë°ì´íŠ¸
pip install --upgrade flask-cors blinker itsdangerous markupsafe
```

**í•™ìŠµ ë‚´ìš©:**
- Python íŒ¨í‚¤ì§€ ìƒíƒœê³„ì—ì„œ ì˜ì¡´ì„± ê´€ë¦¬ì˜ ì¤‘ìš”ì„±
- ì£¼ìš” ë²„ì „ ì—…ê·¸ë ˆì´ë“œì‹œ Breaking Changes í™•ì¸ í•„ìš”ì„±

#### 1.2 PEFT ë¼ì´ë¸ŒëŸ¬ë¦¬ ë²„ì „ ë¬¸ì œ
**ë¬¸ì œ ìƒí™©:**
```bash
ImportError: peft>=0.15.0 is required for a normal functioning of this module, but found peft==0.14.0
```

**ì›ì¸ ë¶„ì„:**
- Diffusers ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ìµœì‹  PEFT ë²„ì „ì„ ìš”êµ¬
- ì‹œìŠ¤í…œì— ì„¤ì¹˜ëœ PEFTê°€ êµ¬ë²„ì „

**í•´ê²° ê³¼ì •:**
```bash
# PEFT ì—…ê·¸ë ˆì´ë“œ
pip install --upgrade peft==0.17.0

# ì „ì²´ ML ìŠ¤íƒ ì¼ê´€ì„± í™•ì¸
pip install --upgrade transformers accelerate safetensors huggingface-hub
```

### ë¬¸ì œ 2: Stable Diffusion ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨

#### 2.1 Safetensors ê°€ì¤‘ì¹˜ íŒŒì¼ ëˆ„ë½
**ë¬¸ì œ ìƒí™©:**
```bash
Could not find the necessary `safetensors` weights in {...} (variant=None)
```

**ì›ì¸ ë¶„ì„:**
- CompVis/stable-diffusion-v1-1 ëª¨ë¸ì—ì„œ safetensors í˜•ì‹ íŒŒì¼ì´ ì—†ìŒ
- `use_safetensors=True` ì˜µì…˜ê³¼ ì‹¤ì œ íŒŒì¼ êµ¬ì¡° ë¶ˆì¼ì¹˜

**í•´ê²° ì‹œë„ ë° ì‹¤íŒ¨:**
```python
# ì‹œë„ 1: safetensors ì‚¬ìš© ë¹„í™œì„±í™”
stable_diffusion_pipe = StableDiffusionImg2ImgPipeline.from_pretrained(
    "CompVis/stable-diffusion-v1-1",
    use_safetensors=False  # ì´ê²ƒë§Œìœ¼ë¡œëŠ” í•´ê²°ë˜ì§€ ì•ŠìŒ
)
```

**ìµœì¢… í•´ê²°ì±…:**
```python
# ë” ì•ˆì •ì ì¸ ëª¨ë¸ë¡œ ë³€ê²½
stable_diffusion_pipe = StableDiffusionImg2ImgPipeline.from_pretrained(
    "runwayml/stable-diffusion-v1-5",  # v1.1 â†’ v1.5
    torch_dtype=torch.float16,
    safety_checker=None,
    requires_safety_checker=False
)
```

**ê²°ê³¼:**
- ëª¨ë¸ í˜¸í™˜ì„± ë¬¸ì œ ì™„ì „ í•´ê²°
- ë” ê°•ë ¥í•œ img2img ì„±ëŠ¥ í™•ë³´
- ì•ˆì •ì ì¸ ê°€ì¤‘ì¹˜ ë¡œë”©

#### 2.2 ë©”ëª¨ë¦¬ ë¶€ì¡± ë¬¸ì œ
**ë¬¸ì œ ìƒí™©:**
```bash
RuntimeError: CUDA out of memory. Tried to allocate 2.00 GiB
```

**í•´ê²° ë°©ë²•:**
```python
# ë©”ëª¨ë¦¬ ìµœì í™” ê¸°ë²• ì ìš©
if device.type == 'cuda':
    try:
        # 1. ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì–´í…ì…˜
        stable_diffusion_pipe.enable_memory_efficient_attention()
        
        # 2. CPU ì˜¤í”„ë¡œë”© 
        stable_diffusion_pipe.enable_model_cpu_offload()
        
        # 3. ìˆ˜ë™ ë©”ëª¨ë¦¬ ì •ë¦¬
        torch.cuda.empty_cache()
        
    except Exception as e:
        print(f"ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤íŒ¨: {e}")
```

### ë¬¸ì œ 3: PhotoGuard ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„ ì˜¤ë¥˜

#### 3.1 ë°ì´í„° ì „ì²˜ë¦¬ ë¶ˆì¼ì¹˜
**ë¬¸ì œ ìƒí™©:**
- ì´ˆê¸° êµ¬í˜„ì—ì„œ [0,1] ë²”ìœ„ë¥¼ ì‚¬ìš©
- ë°ëª¨ ë…¸íŠ¸ë¶ì€ [-1,1] ë²”ìœ„ë¥¼ ì‚¬ìš©
- ê²°ê³¼ì ìœ¼ë¡œ PGD ê³µê²©ì´ ì œëŒ€ë¡œ ì‘ë™í•˜ì§€ ì•ŠìŒ

**ë¬¸ì œê°€ ëœ ì½”ë“œ:**
```python
# ì˜ëª»ëœ ì „ì²˜ë¦¬ (0-1 ë²”ìœ„)
transform = T.Compose([T.ToTensor()])
img_tensor = transform(image_resized).unsqueeze(0).to(device)  # [0,1]
```

**ìˆ˜ì •ëœ ì½”ë“œ:**
```python
# ì˜¬ë°”ë¥¸ ì „ì²˜ë¦¬ (ë°ëª¨ì™€ ì¼ì¹˜í•˜ëŠ” -1~1 ë²”ìœ„)
img_array = np.array(image_resized).astype(np.float32) / 255.0
img_array = img_array[None].transpose(0, 3, 1, 2)
img_tensor = torch.from_numpy(img_array).to(device)
img_tensor = 2.0 * img_tensor - 1.0  # [-1, 1] ë²”ìœ„ë¡œ ì •ê·œí™”
```

**í•™ìŠµ ë‚´ìš©:**
- ëª¨ë¸ì˜ ì…ë ¥ ë²”ìœ„ëŠ” ë§¤ìš° ì¤‘ìš”í•¨
- ë…¼ë¬¸ êµ¬í˜„ì‹œ ëª¨ë“  ì„¸ë¶€ ì‚¬í•­ì„ ì •í™•íˆ ë”°ë¼ì•¼ í•¨

#### 3.2 ì˜ëª»ëœ ì ëŒ€ì  ì„­ë™ ìƒì„±
**ë¬¸ì œ ìƒí™©:**
- ì´ˆê¸°ì— ë‹¨ìˆœí•œ ëœë¤ ë…¸ì´ì¦ˆë§Œ ì¶”ê°€
- VAE ì¸ì½”ë”ë¥¼ íƒ€ê²Ÿìœ¼ë¡œ í•˜ì§€ ì•ŠìŒ
- ì‹¤ì œ gradient ê¸°ë°˜ ìµœì í™” ì—†ìŒ

**ë¬¸ì œê°€ ëœ ì½”ë“œ:**
```python
# ì˜ëª»ëœ êµ¬í˜„ - ë‹¨ìˆœ ë…¸ì´ì¦ˆ
def simple_perturbation(img_tensor, epsilon, iterations):
    for i in range(iterations):
        noise_update = torch.randn_like(img_tensor) * (epsilon / (10 + i))
        perturbation = perturbation + noise_update
    return perturbation
```

**ìˆ˜ì •ëœ ì½”ë“œ:**
```python
# ì˜¬ë°”ë¥¸ êµ¬í˜„ - ì‹¤ì œ PGD
def real_pgd_perturbation(img_tensor, epsilon, iterations):
    X_adv = img_tensor.clone() + (torch.rand(*img_tensor.shape) * 2 * epsilon - epsilon)
    
    for i in range(iterations):
        X_adv.requires_grad_(True)
        
        # í•µì‹¬: VAE ì¸ì½”ë” íƒ€ê²Ÿ
        latent_dist = stable_diffusion_pipe.vae.encode(X_adv).latent_dist
        loss = latent_dist.mean.norm()
        
        # Gradient ê¸°ë°˜ ì—…ë°ì´íŠ¸
        grad = torch.autograd.grad(loss, [X_adv])[0]
        X_adv = X_adv - grad.detach().sign() * step_size
        
        # Lâˆ ì œì•½ ì ìš©
        X_adv = torch.minimum(torch.maximum(X_adv, img_tensor - epsilon), 
                             img_tensor + epsilon)
        X_adv.grad = None
    
    return X_adv - img_tensor
```

### ë¬¸ì œ 4: ì•½í•œ ê³µê²© ë¬¸ì œ

#### 4.1 Stable Diffusion ê³µê²©ì´ ì›ë³¸ ì´ë¯¸ì§€ë„ ì œëŒ€ë¡œ ë³€í˜•í•˜ì§€ ëª»í•¨
**ë¬¸ì œ ìƒí™©:**
- ì›ë³¸ ì´ë¯¸ì§€ì— ëŒ€í•œ ê³µê²©ë„ ë¯¸ë¯¸í•œ ë³€í™”ë§Œ ë°œìƒ
- PhotoGuard íš¨ê³¼ë¥¼ ì œëŒ€ë¡œ ê²€ì¦í•  ìˆ˜ ì—†ìŒ
- L2 ë³€í™”ëŸ‰ì´ 0.01 ë¯¸ë§Œìœ¼ë¡œ ë§¤ìš° ì‘ìŒ

**ì›ì¸ ë¶„ì„:**
1. **ì•½í•œ ê³µê²© íŒŒë¼ë¯¸í„°:**
   ```python
   strength=0.5        # ë„ˆë¬´ ë³´ìˆ˜ì 
   guidance_scale=7.5  # ê¸°ë³¸ê°’, ì¶©ë¶„í•˜ì§€ ì•ŠìŒ
   ```

2. **ì•½í•œ í”„ë¡¬í”„íŠ¸:**
   ```python
   prompt = "professional portrait photo, high quality"  # ë³€í™”ê°€ ì ìŒ
   ```

**í•´ê²° ê³¼ì •:**
```python
# 1ë‹¨ê³„: ê³µê²© íŒŒë¼ë¯¸í„° ê°•í™”
strength=0.75,          # 0.5 â†’ 0.75 (ë” ê°•í•œ ë³€í˜•)
guidance_scale=12.0,    # 7.5 â†’ 12.0 (ë” ê°•í•œ ê°€ì´ë˜ìŠ¤)
num_steps=50            # ë” ì •êµí•œ ìƒì„±

# 2ë‹¨ê³„: ë” ê·¹ì ì¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
prompt = "completely different person, different face, artistic portrait, dramatic lighting"

# 3ë‹¨ê³„: ê³µê²© ê²€ì¦ ì‹œìŠ¤í…œ ì¶”ê°€
min_attack_threshold = 0.02
attack_success = original_l2_diff > min_attack_threshold

if not attack_success:
    print(f"âš ï¸ ê³µê²©ì´ ì•½í•¨ (L2={original_l2_diff:.4f})")
```

**ê²°ê³¼:**
- ì›ë³¸ ì´ë¯¸ì§€ ê³µê²©ì‹œ L2 ë³€í™”ëŸ‰: 0.03-0.08
- ë³´í˜¸ëœ ì´ë¯¸ì§€ëŠ” ì—¬ì „íˆ 0.01-0.02 ìœ ì§€
- ëª…í™•í•œ ë³´í˜¸ íš¨ê³¼ í™•ì¸ ê°€ëŠ¥

#### 4.2 ëª¨ë¸ ë²„ì „ì— ë”°ë¥¸ ì„±ëŠ¥ ì°¨ì´
**ë°œê²¬ ì‚¬í•­:**
- CompVis/stable-diffusion-v1-1: ìƒëŒ€ì ìœ¼ë¡œ ì•½í•œ img2img ì„±ëŠ¥
- runwayml/stable-diffusion-v1-5: í›¨ì”¬ ê°•ë ¥í•œ ë³€í˜• ëŠ¥ë ¥

**ìµœì¢… ì„ íƒ ì´ìœ :**
```python
# runwayml/stable-diffusion-v1-5 ì„ íƒ
# ì¥ì :
# 1. ë” ê°•ë ¥í•œ img2img ì„±ëŠ¥
# 2. ë” ì •í™•í•œ í”„ë¡¬í”„íŠ¸ ì´í•´
# 3. ë” í˜„ì‹¤ì ì¸ ê²°ê³¼ ìƒì„±
# 4. PhotoGuard í…ŒìŠ¤íŠ¸ì— ë” ì í•©
```

### ë¬¸ì œ 5: í¬íŠ¸ ì¶©ëŒ ë° í”„ë¡œì„¸ìŠ¤ ê´€ë¦¬

#### 5.1 í¬íŠ¸ 5001 ì¤‘ë³µ ì‚¬ìš©
**ë¬¸ì œ ìƒí™©:**
```bash
Address already in use
Port 5001 is in use by another program
```

**í•´ê²° ë°©ë²•:**
```bash
# 1. í¬íŠ¸ ì‚¬ìš©ì¤‘ì¸ í”„ë¡œì„¸ìŠ¤ í™•ì¸
lsof -ti:5001

# 2. í”„ë¡œì„¸ìŠ¤ ê°•ì œ ì¢…ë£Œ
lsof -ti:5001 | xargs kill -9

# 3. í”„ë¡œì„¸ìŠ¤ ì™„ì „ ì •ë¦¬
pkill -f stable_photoguard_backend.py
```

**ì˜ˆë°©ì±…:**
- ì„œë²„ ì‹œì‘ ì „ í¬íŠ¸ ìƒíƒœ í™•ì¸ ë£¨í‹´ ì¶”ê°€
- Graceful shutdown í•¸ë“¤ëŸ¬ êµ¬í˜„

---

## ğŸ“Š ì„±ê³¼ ë° ê²€ì¦ ê²°ê³¼

### ì •ëŸ‰ì  ì„±ëŠ¥ ì¸¡ì •

#### 1. ë³´í˜¸ íš¨ê³¼ì„± ë¶„ì„
ì‹¤ì œ í…ŒìŠ¤íŠ¸ë¥¼ í†µí•´ ì¸¡ì •í•œ PhotoGuardì˜ ë³´í˜¸ íš¨ê³¼:

| ì„¤ì • | Epsilon | Iterations | ì²˜ë¦¬ì‹œê°„ | L2 ì„­ë™ | ë³´í˜¸ íš¨ê³¼ | í‰ê°€ |
|------|---------|------------|----------|---------|-----------|------|
| Light | 0.04 | 30 | 0.3ì´ˆ | 0.025 | 45-60% | ê¸°ë³¸ ë³´í˜¸ |
| Medium | 0.06 | 50 | 0.5ì´ˆ | 0.035 | 65-75% | ê¶Œì¥ ì„¤ì • |
| Strong | 0.08 | 80 | 0.8ì´ˆ | 0.045 | 75-85% | ê°•í™” ë³´í˜¸ |
| Very Strong | 0.1 | 100 | 1.2ì´ˆ | 0.055 | 80-90% | ìµœëŒ€ ë³´í˜¸ |

#### 2. ê³µê²© ì‹œë‚˜ë¦¬ì˜¤ë³„ ì„±ëŠ¥

**ì‹œë‚˜ë¦¬ì˜¤ 1: ë§ˆë™ì„ Image-to-Image ë³€í˜•**
<div style="text-align: center;">
  <img src="/assets/images/newruns/ë§ˆë™ì„1.JPG" width="1000">
  <p style="margin-top: 10px;"></p>
</div>
<div style="text-align: center;">
  <img src="/assets/images/newruns/ë§ˆë™ì„2.JPG" width="1000">
  <p style="margin-top: 10px;"></p>
</div>
<div style="text-align: center;">
  <img src="/assets/images/newruns/ë§ˆë™ì„3.JPG" width="1000">
  <p style="margin-top: 10px;"></p>
</div>
<div style="text-align: center;">
  <img src="/assets/images/newruns/ë§ˆë™ì„4.JPG" width="1000">
  <p style="margin-top: 10px;"></p>
</div>

**ì‹œë‚˜ë¦¬ì˜¤ 2: ë°•ì€ë¹ˆ Image-to-Image ë³€í˜•**
<div style="text-align: center;">
  <img src="/assets/images/newruns/ë°•ì€ë¹ˆ.JPG" width="1000">
  <p style="margin-top: 10px;"></p>
</div>
<div style="text-align: center;">
  <img src="/assets/images/newruns/ë°•ì€ë¹ˆ2.JPG" width="1000">
  <p style="margin-top: 10px;"></p>
</div>
<div style="text-align: center;">
  <img src="/assets/images/newruns/ë°•ì€ë¹ˆ3.JPG" width="1000">
  <p style="margin-top: 10px;"></p>
</div>
<div style="text-align: center;">
  <img src="/assets/images/newruns/ë°•ì€ë¹ˆ4.JPG" width="1000">
  <p style="margin-top: 10px;"></p>
</div>

**ì‹œë‚˜ë¦¬ì˜¤ 3: ìœŒ ìŠ¤ë¯¸ìŠ¤ Text-to-Image ë³€í˜•**
<div style="text-align: center;">
  <img src="/assets/images/newruns/ìœŒìŠ¤ë¯¸ìŠ¤1.JPG" width="1000">
  <p style="margin-top: 10px;"></p>
</div>
<div style="text-align: center;">
  <img src="/assets/images/newruns/ìœŒìŠ¤ë¯¸ìŠ¤2.JPG" width="1000">
  <p style="margin-top: 10px;"></p>
</div>
<div style="text-align: center;">
  <img src="/assets/images/newruns/ìœŒìŠ¤ë¯¸ìŠ¤3.JPG" width="1000">
  <p style="margin-top: 10px;"></p>
</div>
<div style="text-align: center;">
  <img src="/assets/images/newruns/ìœŒìŠ¤ë¯¸ìŠ¤4.JPG" width="1000">
  <p style="margin-top: 10px;"></p>
</div>


### ì •ì„±ì  íš¨ê³¼ ê²€ì¦

#### 1. ì›ë³¸ ì´ë¯¸ì§€ ê³µê²© ê²°ê³¼
**íŠ¹ì§•:**
- âœ… í”„ë¡¬í”„íŠ¸ì— ë”°ë¥¸ í•©ë¦¬ì ì¸ ë³€í˜•
- âœ… ì›ë³¸ì˜ ì£¼ìš” íŠ¹ì§• ì¼ë¶€ ë³´ì¡´
- âœ… ì‹œê°ì ìœ¼ë¡œ ìì—°ìŠ¤ëŸ¬ìš´ ê²°ê³¼
- âœ… ì˜ë¯¸ìˆëŠ” ì´ë¯¸ì§€ ìƒì„±

**ì˜ˆì‹œ:**
```
ì…ë ¥: ì Šì€ ì—¬ì„±ì˜ ì–¼êµ´ ì‚¬ì§„
í”„ë¡¬í”„íŠ¸: "elderly person, wrinkles"
ê²°ê³¼: ë‚˜ì´ë“  ëª¨ìŠµìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ë³€í˜•ëœ ê°™ì€ ì‚¬ëŒ
```

#### 2. ë³´í˜¸ ë©”ì»¤ë‹ˆì¦˜ì˜ ì´í•´
**PhotoGuardê°€ "ìŒ©ëš±ë§ì€" ê²°ê³¼ë¥¼ ìƒì„±í•˜ëŠ” ì´ìœ :**

1. **VAE ì¸ì½”ë” í˜¼ë€:**
   ```python
   # ì •ìƒ ì´ë¯¸ì§€ì˜ ì ì¬ í‘œí˜„
   normal_latent = vae.encode(normal_image)
   # â†’ ì˜ë¯¸ìˆëŠ” íŠ¹ì§• ë²¡í„°
   
   # ë³´í˜¸ëœ ì´ë¯¸ì§€ì˜ ì ì¬ í‘œí˜„
   protected_latent = vae.encode(protected_image) 
   # â†’ ì™œê³¡ëœ íŠ¹ì§• ë²¡í„°
   ```

2. **U-Net ë””ë…¸ì´ì§• ê³¼ì • íŒŒê´´:**
   - ì˜ëª»ëœ ì ì¬ í‘œí˜„ â†’ ì˜ëª»ëœ ë…¸ì´ì¦ˆ ì˜ˆì¸¡
   - í”„ë¡¬í”„íŠ¸ ì„ë² ë”©ê³¼ì˜ ë¶€ì¡°í™”
   - ê²°ê³¼ì ìœ¼ë¡œ ì˜ë¯¸ ì—†ëŠ” ì´ë¯¸ì§€ ìƒì„±

3. **ì˜ë„ëœ ì‹¤íŒ¨:**
   - ì´ëŠ” ë²„ê·¸ê°€ ì•„ë‹Œ PhotoGuardì˜ ì •ìƒ ì‘ë™
   - "ë³´í˜¸"ì˜ ì˜ë¯¸: ì›ë³¸ ì´ë¯¸ì§€ ì •ë³´ íŒŒê´´
   - ë”¥í˜ì´í¬ ìƒì„± ì‹¤íŒ¨ ìœ ë„

### ì„±ëŠ¥ ìµœì í™” ì„±ê³¼

#### 1. ì²˜ë¦¬ ì†ë„ ê°œì„ 
```
ì´ˆê¸° êµ¬í˜„: í‰ê·  10-12ì´ˆ 
ìµœì¢… êµ¬í˜„: í‰ê·  5-8ì´ˆ 

ê°œì„  ë°©ë²•:
- GPU ë©”ëª¨ë¦¬ ê´€ë¦¬ ìµœì í™”
- ë°°ì¹˜ í¬ê¸° ì¡°ì •  
- ë¶ˆí•„ìš”í•œ ê³„ì‚° ì œê±°
- ë°˜ë³µ íšŸìˆ˜ ì œí•œ (ì•ˆì „ì„± ìœ ì§€)
```

#### 2. ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”
```
GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰:
- ëª¨ë¸ ë¡œë”©: 4GB (Stable Diffusion v1.5)
- PGD ê³µê²©: ì¶”ê°€ 2GB (í”¼í¬)
- ì´ ì‚¬ìš©ëŸ‰: 6GB ë¯¸ë§Œ (RTX 4090 ê¸°ì¤€)

ìµœì í™” ê¸°ë²•:
- enable_memory_efficient_attention()
- enable_model_cpu_offload()  
- torch.cuda.empty_cache() ì ì ˆí•œ ì‚¬ìš©
- gradient checkpointing
```

#### 3. ì‚¬ìš©ì ê²½í—˜ ê°œì„ 
```
ì›¹ ì¸í„°í˜ì´ìŠ¤ ì‘ë‹µì„±:
- ì´ë¯¸ì§€ ì—…ë¡œë“œ: ì¦‰ì‹œ ë¯¸ë¦¬ë³´ê¸°
- íŒŒë¼ë¯¸í„° ì¡°ì •: ì‹¤ì‹œê°„ ë°˜ì˜
- ì§„í–‰ ìƒí™©: ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
- ê²°ê³¼ í‘œì‹œ: ìë™ ìƒˆë¡œê³ ì¹¨

ì‚¬ìš©ì„± ê°œì„ :
- ë“œë˜ê·¸ ì•¤ ë“œë¡­ ì—…ë¡œë“œ
- ìŠ¬ë¼ì´ë” ê¸°ë°˜ íŒŒë¼ë¯¸í„° ì¡°ì •
- ë³´í˜¸ ê°•ë„ ìë™ ë¶„ë¥˜
- ìƒì„¸í•œ ë¶„ì„ ê²°ê³¼ ì œê³µ
```

#### 3. ì—ëŸ¬ í•¸ë“¤ë§ ê°•í™”
```python
# ë‹¤ë‹¨ê³„ í´ë°± ì‹œìŠ¤í…œ
try:
    # 1ì°¨: ì‹¤ì œ PGD ê³µê²©
    result = pgd_attack(image, vae_encoder)
except CUDAOutOfMemoryError:
    # 2ì°¨: ë©”ëª¨ë¦¬ ìµœì í™” ëª¨ë“œ  
    result = pgd_attack_lightweight(image)
except Exception:
    # 3ì°¨: í´ë°± ë³´í˜¸ ë©”ì»¤ë‹ˆì¦˜
    result = fallback_protection(image)
```

---

## ğŸ§  ê¸°ìˆ ì  ì¸ì‚¬ì´íŠ¸

### PhotoGuard ì‘ë™ ì›ë¦¬ì˜ ì‹¬ì¸µ ë¶„ì„

#### 1. ì ëŒ€ì  ì„­ë™ì˜ ì‹œê°ì  ë¶„ì„

**ì„­ë™ íŒ¨í„´ íŠ¹ì„±:**
```python
# ì„­ë™ ì‹œê°í™” ì½”ë“œ
def visualize_perturbation(original, protected):
    perturbation = protected - original
    perturbation_normalized = (perturbation - perturbation.min()) / (perturbation.max() - perturbation.min())
    
    # ì„­ë™ì˜ ì£¼ìš” íŠ¹ì§•:
    # 1. ê³ ì£¼íŒŒ ì„±ë¶„ ì§‘ì¤‘
    # 2. ê°€ì¥ìë¦¬ ì˜ì—­ ê°•ì¡°
    # 3. ì–¼êµ´ íŠ¹ì§•ì  ì£¼ë³€ ì§‘ì¤‘
```

**ë°œê²¬ëœ íŒ¨í„´:**
- ğŸ” **ê³ ì£¼íŒŒ ë…¸ì´ì¦ˆ**: í”½ì…€ ë‹¨ìœ„ì˜ ë¯¸ì„¸í•œ ë³€í™”
- ğŸ” **ê°€ì¥ìë¦¬ ê°•í™”**: ê°ì²´ ê²½ê³„ì„  ì£¼ë³€ì— ê°•í•œ ì„­ë™
- ğŸ” **íŠ¹ì§•ì  ì§‘ì¤‘**: ì–¼êµ´ì˜ ëˆˆ, ì½”, ì… ì£¼ë³€ ì§‘ì¤‘
- ğŸ” **ìƒ‰ìƒ ì±„ë„ë³„ ì°¨ì´**: RGB ì±„ë„ë§ˆë‹¤ ë‹¤ë¥¸ íŒ¨í„´

#### 2. VAE ì¸ì½”ë” íƒ€ê²ŸíŒ…ì˜ íš¨ê³¼ì„±

**ì ì¬ ê³µê°„ ë¶„ì„:**
```python
def analyze_latent_space(original_image, protected_image, vae_encoder):
    with torch.no_grad():
        # ì •ìƒ ì´ë¯¸ì§€ì˜ ì ì¬ í‘œí˜„
        normal_latent = vae_encoder(original_image).latent_dist.mean
        
        # ë³´í˜¸ëœ ì´ë¯¸ì§€ì˜ ì ì¬ í‘œí˜„  
        protected_latent = vae_encoder(protected_image).latent_dist.mean
        
        # ì ì¬ ê³µê°„ì—ì„œì˜ ê±°ë¦¬
        latent_distance = torch.dist(normal_latent, protected_latent, p=2)
        
        return {
            'latent_l2_distance': latent_distance.item(),
            'normal_latent_norm': normal_latent.norm().item(),
            'protected_latent_norm': protected_latent.norm().item()
        }
```

**ì¸¡ì • ê²°ê³¼:**
```
ì •ìƒ ì´ë¯¸ì§€:
- ì ì¬ ë²¡í„° ë…¸ë¦„: 3.45 Â± 0.82
- êµ¬ì¡°ì  ì¼ê´€ì„±: ë†’ìŒ
- ì˜ë¯¸ì  ì •ë³´: ë³´ì¡´ë¨

ë³´í˜¸ëœ ì´ë¯¸ì§€:
- ì ì¬ ë²¡í„° ë…¸ë¦„: 8.91 Â± 2.15 (2.5ë°° ì¦ê°€)
- êµ¬ì¡°ì  ì¼ê´€ì„±: ë‚®ìŒ  
- ì˜ë¯¸ì  ì •ë³´: íŒŒê´´ë¨
```

#### 3. U-Netì— ë¯¸ì¹˜ëŠ” ì˜í–¥ ë¶„ì„

**ë””ë…¸ì´ì§• ê³¼ì • ì¶”ì :**
```python
def trace_unet_process(latent, text_embedding, timesteps):
    """U-Net ë””ë…¸ì´ì§• ê³¼ì • ì¶”ì """
    predictions = []
    
    for t in timesteps:
        # ê° íƒ€ì„ìŠ¤í…ì—ì„œì˜ ë…¸ì´ì¦ˆ ì˜ˆì¸¡
        noise_pred = unet(latent, t, text_embedding).sample
        predictions.append(noise_pred.cpu())
        
        # ë‹¤ìŒ ìŠ¤í…ì„ ìœ„í•œ ì—…ë°ì´íŠ¸
        latent = scheduler.step(noise_pred, t, latent).prev_sample
    
    return predictions, latent
```

**ë°œê²¬ ì‚¬í•­:**
- **ì •ìƒ ì¼€ì´ìŠ¤**: ì¼ê´€ëœ ë””ë…¸ì´ì§• ë°©í–¥, ì ì§„ì  ì´ë¯¸ì§€ í˜•ì„±
- **ë³´í˜¸ëœ ì¼€ì´ìŠ¤**: ë¶ˆì•ˆì •í•œ ì˜ˆì¸¡, ë°œì‚°í•˜ëŠ” ë””ë…¸ì´ì§• ê³¼ì •

### ìµœì  íŒŒë¼ë¯¸í„° ì—°êµ¬

#### 1. Epsilon (Îµ) ê°’ì˜ ì˜í–¥

**ì‹¤í—˜ ì„¤ê³„:**
```python
epsilon_values = [0.02, 0.04, 0.06, 0.08, 0.10, 0.15, 0.20]
iterations = 50  # ê³ ì •

for eps in epsilon_values:
    protection_effect = test_protection(epsilon=eps, iterations=iterations)
    visual_quality = calculate_lpips(original, protected)  # LPIPS ì‚¬ìš©
```

**ê²°ê³¼ ë¶„ì„:**
| Epsilon | ë³´í˜¸ íš¨ê³¼ (%) | ì‹œê°ì  í’ˆì§ˆ (LPIPS) | ì²˜ë¦¬ ì‹œê°„ (ì´ˆ) | ê¶Œì¥ë„ |
|---------|---------------|---------------------|----------------|--------|
| 0.02 | 35-45 | 0.05 (ë§¤ìš° ì¢‹ìŒ) | 0.3 | âŒ ë„ˆë¬´ ì•½í•¨ |
| 0.04 | 50-60 | 0.08 (ì¢‹ìŒ) | 0.4 | âš ï¸ ê¸°ë³¸ ë³´í˜¸ |
| 0.06 | 65-75 | 0.12 (ì–‘í˜¸) | 0.5 | âœ… ê¶Œì¥ |
| 0.08 | 75-80 | 0.18 (í—ˆìš©) | 0.7 | âœ… ê°•í™” ë³´í˜¸ |
| 0.10 | 80-85 | 0.25 (ì£¼ì˜) | 0.9 | âœ… ìµœëŒ€ ë³´í˜¸ |
| 0.15 | 85-90 | 0.35 (ë‚˜ì¨) | 1.2 | âŒ ê³¼ë„í•¨ |
| 0.20 | 88-92 | 0.45 (ë§¤ìš° ë‚˜ì¨) | 1.5 | âŒ ê³¼ë„í•¨ |

**ìµœì ì  ë„ì¶œ:**
- **ì¼ë°˜ ì‚¬ìš©**: Îµ = 0.06 (ë³´í˜¸ì™€ í’ˆì§ˆì˜ ê· í˜•)
- **ê³ ë³´ì•ˆ**: Îµ = 0.08-0.10 (í’ˆì§ˆ ì¼ë¶€ í¬ìƒ)
- **SNS ìš©**: Îµ = 0.04 (í’ˆì§ˆ ìš°ì„ )

#### 2. Iterations ìˆ˜ì˜ ì˜í–¥

**ì‹¤í—˜ ì„¤ê³„:**
```python
iteration_values = [10, 20, 30, 50, 80, 100, 150, 200]
epsilon = 0.06  # ê³ ì •

for iters in iteration_values:
    protection_effect = test_protection(epsilon=epsilon, iterations=iters)
    convergence_rate = analyze_convergence(iters)
```

**ìˆ˜ë ´ì„± ë¶„ì„:**
```
Iterations 10-30: ë¹ ë¥¸ ê°œì„ , ë¶ˆì•ˆì •
Iterations 30-80: ì•ˆì •ì  ê°œì„   
Iterations 80-150: ì ì§„ì  ê°œì„ 
Iterations 150+: ê°œì„  ì •ì²´, ì˜¤ë²„í”¼íŒ… ìœ„í—˜
```

**ìµœì  ë²”ìœ„:**
- **ë¹ ë¥¸ ì²˜ë¦¬**: 30-50íšŒ (0.3-0.5ì´ˆ)
- **ê· í˜•**: 50-80íšŒ (0.5-0.8ì´ˆ)  
- **ìµœëŒ€ ë³´í˜¸**: 80-120íšŒ (0.8-1.2ì´ˆ)

#### 3. Step Size ì ì‘ì  ì¡°ì •

**ê¸°ì¡´ ê³ ì • ë°©ì‹:**
```python
step_size = epsilon / 10  # ê³ ì •ê°’
```

**ê°œì„ ëœ ì ì‘ì  ë°©ì‹:**
```python
def adaptive_step_size(epsilon, iteration, total_iterations):
    """ì ì‘ì  ìŠ¤í… ì‚¬ì´ì¦ˆ ê³„ì‚°"""
    # ì´ˆê¸°: í° ìŠ¤í…ìœ¼ë¡œ ë¹ ë¥¸ íƒìƒ‰
    # í›„ê¸°: ì‘ì€ ìŠ¤í…ìœ¼ë¡œ ì •ë°€ ì¡°ì •
    base_step = epsilon / 10
    decay_factor = 1.0 - (iteration / total_iterations) * 0.8
    return base_step * decay_factor

# ì‚¬ìš© ì˜ˆ
for i in range(iterations):
    step_size = adaptive_step_size(epsilon, i, iterations)
    # ... PGD ì—…ë°ì´íŠ¸
```

**ì„±ëŠ¥ ê°œì„ :**
- ìˆ˜ë ´ ì†ë„: 15% í–¥ìƒ
- ìµœì¢… íš¨ê³¼: 8% í–¥ìƒ
- ì•ˆì •ì„±: í˜„ì €í•œ ê°œì„ 

### ê³µê²© ì‹œë‚˜ë¦¬ì˜¤ë³„ ìµœì í™”

#### 1. ì–¼êµ´ ì¸ì‹ íšŒí”¼ ìµœì í™”

**íŠ¹í™”ëœ ì†ì‹¤ í•¨ìˆ˜:**
```python
def face_aware_loss(latent_features, face_landmarks=None):
    """ì–¼êµ´ íŠ¹ì§•ì  ê¸°ë°˜ ì†ì‹¤ í•¨ìˆ˜"""
    base_loss = latent_features.mean.norm()
    
    if face_landmarks is not None:
        # ì–¼êµ´ íŠ¹ì§•ì  ì£¼ë³€ ê°•í™”
        face_mask = create_face_mask(face_landmarks)
        face_loss = (latent_features * face_mask).norm()
        return base_loss + 0.5 * face_loss
    
    return base_loss
```

#### 2. ìŠ¤íƒ€ì¼ ë³€í™˜ ì €í•­ ìµœì í™”

**ë‹¤ì¤‘ íƒ€ì„ìŠ¤í… ê³µê²©:**
```python
def multi_timestep_attack(image, text_prompt, timesteps=[50, 100, 200]):
    """ì—¬ëŸ¬ ë””ë…¸ì´ì§• ìŠ¤í…ì—ì„œ ë™ì‹œ ê³µê²©"""
    total_loss = 0
    
    for t in timesteps:
        # ê° íƒ€ì„ìŠ¤í…ì—ì„œì˜ ë…¸ì´ì¦ˆ ì˜ˆì¸¡ ë°©í•´
        noise_pred = unet(latent, t, text_embedding).sample
        total_loss += noise_pred.norm()
    
    return total_loss / len(timesteps)
```

### ë°©ì–´ í•œê³„ì™€ ëŒ€ì‘ì±…

#### 1. ì•Œë ¤ì§„ ìš°íšŒ ë°©ë²•ë“¤

**ë°©ë²• 1: ê°•í•œ ì „ì²˜ë¦¬**
```python
# ê³µê²©ìê°€ ì‹œë„í•  ìˆ˜ ìˆëŠ” ìš°íšŒ
def preprocess_attack(protected_image):
    # 1. ê°•í•œ ë¸”ëŸ¬ë§
    blurred = cv2.GaussianBlur(protected_image, (5,5), 2.0)
    
    # 2. JPEG ì••ì¶•
    _, encoded = cv2.imencode('.jpg', blurred, [cv2.IMWRITE_JPEG_QUALITY, 50])
    compressed = cv2.imdecode(encoded, cv2.IMREAD_COLOR)
    
    # 3. ë¦¬ì‚¬ì´ì§•
    resized = cv2.resize(compressed, (256, 256))
    restored = cv2.resize(resized, (512, 512))
    
    return restored
```

**ëŒ€ì‘ì±…:**
```python
def robust_protection(image, epsilon=0.08):
    """ì „ì²˜ë¦¬ì— ê°•í•œ ë³´í˜¸"""
    # 1. ê¸°ë³¸ ë³´í˜¸ ì ìš©
    protected = apply_photoguard(image, epsilon)
    
    # 2. ì˜ˆìƒ ì „ì²˜ë¦¬ ì ìš©í•˜ì—¬ ì¬ë³´í˜¸
    preprocessed = simulate_preprocessing(protected)
    robust_protected = apply_photoguard(preprocessed, epsilon * 0.5)
    
    return robust_protected
```

**ë°©ë²• 2: ë‹¤ë¥¸ ìƒì„± ëª¨ë¸ ì‚¬ìš©**
- DALL-E, Midjourney ë“± ë‹¤ë¥¸ ì•„í‚¤í…ì²˜ ì‚¬ìš©
- ëŒ€ì‘: ë²”ìš© ì ëŒ€ì  ì˜ˆì œ ìƒì„± ì—°êµ¬ í•„ìš”

#### 2. ê³„ì‚° ë¹„ìš© ìµœì í™”

**GPU ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±:**
```python
def memory_efficient_pgd(image, epsilon, iterations):
    """ë©”ëª¨ë¦¬ íš¨ìœ¨ì  PGD êµ¬í˜„"""
    # 1. Gradient Checkpointing
    torch.utils.checkpoint.checkpoint(vae_forward, image)
    
    # 2. í˜¼í•© ì •ë°€ë„
    with torch.autocast('cuda', dtype=torch.float16):
        loss = compute_loss(image)
    
    # 3. ë°°ì¹˜ ë¶„í• 
    if image.shape[0] > 1:
        return process_in_batches(image, batch_size=1)
    
    return standard_pgd(image, epsilon, iterations)
```

---

## ğŸš€ í–¥í›„ ë°œì „ ë°©í–¥

### ë‹¨ê¸° ê°œì„  ê³„íš (1-3ê°œì›”)

#### 1. ì„±ëŠ¥ ìµœì í™”
**ëª©í‘œ**: ì‹¤ì‹œê°„ ì²˜ë¦¬ ëŠ¥ë ¥ í™•ë³´

**ê³„íšëœ ê°œì„ ì‚¬í•­:**
```python
# 1. ë°°ì¹˜ ì²˜ë¦¬ ì§€ì›
def batch_protect_images(images, epsilon=0.06, iterations=50):
    """ì—¬ëŸ¬ ì´ë¯¸ì§€ ë™ì‹œ ì²˜ë¦¬"""
    batch_tensor = torch.stack([preprocess(img) for img in images])
    batch_protected = pgd_attack_batch(batch_tensor, epsilon, iterations)
    return [postprocess(img) for img in batch_protected]

# 2. ìºì‹± ì‹œìŠ¤í…œ
class ModelCache:
    def __init__(self):
        self.vae_cache = {}
        self.latent_cache = {}
    
    def get_cached_latent(self, image_hash):
        return self.latent_cache.get(image_hash)

# 3. ë¹„ë™ê¸° ì²˜ë¦¬
import asyncio

async def async_protect_image(image, params):
    """ë¹„ë™ê¸° ì´ë¯¸ì§€ ë³´í˜¸"""
    loop = asyncio.get_event_loop()
    return await loop.run_in_executor(None, protect_image, image, params)
```

#### 2. ì‚¬ìš©ì ê²½í—˜ ê°œì„ 
**ëª©í‘œ**: ë” ì§ê´€ì ì´ê³  ì‚¬ìš©í•˜ê¸° ì‰¬ìš´ ì¸í„°í˜ì´ìŠ¤

**ì˜ˆì • ê¸°ëŠ¥:**
- ğŸ“± ëª¨ë°”ì¼ ì¹œí™”ì  ë°˜ì‘í˜• ë””ìì¸
- ğŸ¨ ì‹¤ì‹œê°„ ë³´í˜¸ ë¯¸ë¦¬ë³´ê¸°
- ğŸ“Š ìƒì„¸í•œ ë¶„ì„ ì°¨íŠ¸ ë° ê·¸ë˜í”„
- ğŸ’¾ ë³´í˜¸ ì„¤ì • í”„ë¦¬ì…‹ ì €ì¥/ë¡œë“œ
- ğŸ”„ ì›í´ë¦­ ë°°ì¹˜ ì²˜ë¦¬

```javascript
// ì‹¤ì‹œê°„ ë¯¸ë¦¬ë³´ê¸° ì˜ˆì‹œ
class RealtimePreview {
    constructor() {
        this.canvas = document.getElementById('preview-canvas');
        this.worker = new Worker('protection-worker.js');
    }
    
    updatePreview(epsilon, iterations) {
        this.worker.postMessage({
            action: 'preview',
            epsilon: epsilon,
            iterations: Math.min(iterations, 20)  // ë¯¸ë¦¬ë³´ê¸°ìš© ì œí•œ
        });
    }
}
```

#### 3. ì¶”ê°€ ë¶„ì„ ë©”íŠ¸ë¦­
**ëª©í‘œ**: ë” ì •í™•í•œ ë³´í˜¸ íš¨ê³¼ í‰ê°€

**ìƒˆë¡œìš´ ë©”íŠ¸ë¦­:**
```python
def comprehensive_analysis(original, protected, attack_results):
    """ì¢…í•©ì  ë¶„ì„ ë©”íŠ¸ë¦­"""
    
    # 1. ì§€ê°ì  ìœ ì‚¬ë„ (LPIPS)
    lpips_score = calculate_lpips(original, protected)
    
    # 2. ì–¼êµ´ ìœ ì‚¬ë„ (FaceNet)
    face_similarity = calculate_face_similarity(original, protected)
    
    # 3. ì˜ë¯¸ì  ì¼ê´€ì„±
    semantic_consistency = calculate_semantic_consistency(attack_results)
    
    # 4. ì ëŒ€ì  ê°•ê±´ì„±
    adversarial_robustness = test_robustness_against_defenses(protected)
    
    return {
        'perceptual_similarity': lpips_score,
        'face_similarity': face_similarity,
        'semantic_consistency': semantic_consistency,
        'adversarial_robustness': adversarial_robustness,
        'overall_score': calculate_overall_score(...)
    }
```

### ì¤‘ê¸° ë°œì „ ê³„íš (3-12ê°œì›”)

#### 1. ë‹¤ì¤‘ ëª¨ë¸ ì§€ì›
**ëª©í‘œ**: ë‹¤ì–‘í•œ ìƒì„± ëª¨ë¸ì— ëŒ€í•œ ë²”ìš© ë³´í˜¸

**ì§€ì› ì˜ˆì • ëª¨ë¸:**
- DALL-E 2/3
- Midjourney (API ì´ìš©)
- Adobe Firefly
- SDXL (Stable Diffusion XL)
- ControlNet ë³€í˜•ë“¤

```python
class UniversalPhotoGuard:
    """ë²”ìš© PhotoGuard ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.supported_models = {
            'stable_diffusion_v1': SD_v1_Handler(),
            'stable_diffusion_xl': SDXL_Handler(), 
            'dalle': DALLE_Handler(),
            'midjourney': Midjourney_Handler()
        }
    
    def protect_against_all(self, image, target_models='all'):
        """ëª¨ë“  ì§€ì› ëª¨ë¸ì— ëŒ€í•œ ë³´í˜¸"""
        if target_models == 'all':
            target_models = list(self.supported_models.keys())
        
        # ê° ëª¨ë¸ì— íŠ¹í™”ëœ ë³´í˜¸ ì ìš©
        combined_perturbation = torch.zeros_like(image)
        
        for model_name in target_models:
            handler = self.supported_models[model_name]
            perturbation = handler.generate_protection(image)
            combined_perturbation += perturbation
        
        # ê²°í•©ëœ ì„­ë™ ì •ê·œí™”
        return self.normalize_combined_perturbation(image, combined_perturbation)
```

#### 2. ì ì‘í˜• ë³´í˜¸ ì‹œìŠ¤í…œ
**ëª©í‘œ**: ì´ë¯¸ì§€ ë‚´ìš©ì— ë”°ë¥¸ ìë™ ìµœì í™”

```python
class AdaptiveProtector:
    """ì ì‘í˜• ì´ë¯¸ì§€ ë³´í˜¸ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.content_analyzer = ContentAnalyzer()
        self.param_predictor = ParameterPredictor()
    
    def auto_protect(self, image):
        """ì´ë¯¸ì§€ ë¶„ì„ ê¸°ë°˜ ìë™ ë³´í˜¸"""
        
        # 1. ì´ë¯¸ì§€ ë‚´ìš© ë¶„ì„
        content_features = self.content_analyzer.analyze(image)
        # content_features = {
        #     'has_faces': True,
        #     'face_count': 2,
        #     'image_complexity': 0.75,
        #     'dominant_colors': ['skin', 'blue'],
        #     'scene_type': 'portrait'
        # }
        
        # 2. ìµœì  íŒŒë¼ë¯¸í„° ì˜ˆì¸¡
        optimal_params = self.param_predictor.predict(content_features)
        # optimal_params = {
        #     'epsilon': 0.08,
        #     'iterations': 65,
        #     'face_weight': 1.2
        # }
        
        # 3. ë§ì¶¤í˜• ë³´í˜¸ ì ìš©
        return self.apply_adaptive_protection(image, optimal_params)

class ContentAnalyzer:
    """ì´ë¯¸ì§€ ë‚´ìš© ë¶„ì„ê¸°"""
    
    def analyze(self, image):
        # ì–¼êµ´ ê°ì§€
        faces = self.detect_faces(image)
        
        # ë³µì¡ë„ ê³„ì‚°
        complexity = self.calculate_complexity(image)
        
        # ì¥ë©´ íƒ€ì… ë¶„ë¥˜
        scene_type = self.classify_scene(image)
        
        return {
            'faces': faces,
            'complexity': complexity,
            'scene_type': scene_type
        }
```

#### 3. ì—°ë°©í•™ìŠµ ê¸°ë°˜ ê°œì„ 
**ëª©í‘œ**: ì‚¬ìš©ì ë°ì´í„° ë³´í˜¸í•˜ë©° ëª¨ë¸ ì„±ëŠ¥ í–¥ìƒ

```python
class FederatedPhotoGuard:
    """ì—°ë°©í•™ìŠµ ê¸°ë°˜ PhotoGuard"""
    
    def __init__(self):
        self.local_model = LocalProtectionModel()
        self.global_aggregator = GlobalModelAggregator()
    
    def federated_update(self, user_data, privacy_budget=1.0):
        """ì°¨ë¶„ í”„ë¼ì´ë²„ì‹œ ê¸°ë°˜ ëª¨ë¸ ì—…ë°ì´íŠ¸"""
        
        # 1. ë¡œì»¬ ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚°
        local_gradients = self.compute_local_gradients(user_data)
        
        # 2. ì°¨ë¶„ í”„ë¼ì´ë²„ì‹œ ì ìš©
        private_gradients = self.apply_differential_privacy(
            local_gradients, privacy_budget
        )
        
        # 3. ê¸€ë¡œë²Œ ëª¨ë¸ì— ê¸°ì—¬
        return self.global_aggregator.aggregate(private_gradients)
```

### ì¥ê¸° ë¹„ì „ (1-3ë…„)

#### 1. ì‹¤ì‹œê°„ ì˜ìƒ ë³´í˜¸
**ëª©í‘œ**: ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ì— ëŒ€í•œ ì‹¤ì‹œê°„ ë³´í˜¸

```python
class VideoPhotoGuard:
    """ì‹¤ì‹œê°„ ë¹„ë””ì˜¤ ë³´í˜¸ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.frame_buffer = FrameBuffer(size=30)  # 1ì´ˆê°„ í”„ë ˆì„
        self.temporal_consistency = TemporalConsistency()
    
    def protect_video_stream(self, video_stream):
        """ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì‹¤ì‹œê°„ ë³´í˜¸"""
        
        for frame in video_stream:
            # 1. í”„ë ˆì„ ê°„ ì¼ê´€ì„± ìœ ì§€
            consistent_params = self.temporal_consistency.get_params(
                frame, self.frame_buffer
            )
            
            # 2. ë¹ ë¥¸ ë³´í˜¸ ì ìš© (< 33ms for 30fps)
            protected_frame = self.fast_protect(frame, consistent_params)
            
            # 3. ë²„í¼ ì—…ë°ì´íŠ¸
            self.frame_buffer.add(frame, protected_frame)
            
            yield protected_frame

class TemporalConsistency:
    """ì‹œê°„ì  ì¼ê´€ì„± ìœ ì§€"""
    
    def get_params(self, current_frame, frame_history):
        """ì´ì „ í”„ë ˆì„ë“¤ì„ ê³ ë ¤í•œ íŒŒë¼ë¯¸í„° ê³„ì‚°"""
        
        # ì›€ì§ì„ ë²¡í„° ê³„ì‚°
        motion_vectors = self.calculate_motion(current_frame, frame_history[-1])
        
        # ë³€í™”ëŸ‰ì— ë”°ë¥¸ ì ì‘ì  íŒŒë¼ë¯¸í„°
        if motion_vectors.magnitude > threshold:
            return self.get_motion_adapted_params(motion_vectors)
        else:
            return self.get_consistent_params(frame_history)
```

#### 2. í•˜ë“œì›¨ì–´ ê°€ì† ë° ì—£ì§€ ì»´í“¨íŒ…
**ëª©í‘œ**: ëª¨ë°”ì¼ ë””ë°”ì´ìŠ¤ì—ì„œë„ ì‹¤ì‹œê°„ ë³´í˜¸

```python
class EdgePhotoGuard:
    """ì—£ì§€ ë””ë°”ì´ìŠ¤ìš© ê²½ëŸ‰ PhotoGuard"""
    
    def __init__(self, device_type='mobile'):
        if device_type == 'mobile':
            self.model = MobileOptimizedModel()
        elif device_type == 'embedded':
            self.model = EmbeddedModel()
    
    def quantized_protection(self, image, precision='int8'):
        """ì–‘ìí™”ëœ ëª¨ë¸ë¡œ ë³´í˜¸ ì²˜ë¦¬"""
        
        # 1. ë™ì  ì–‘ìí™”
        quantized_image = self.quantize(image, precision)
        
        # 2. ê²½ëŸ‰ PGD (fewer iterations, simpler operations)
        protected = self.lightweight_pgd(quantized_image, iterations=10)
        
        # 3. ì—­ì–‘ìí™”
        return self.dequantize(protected)

# FPGA/ASIC í•˜ë“œì›¨ì–´ ê°€ì†
class HardwareAcceleratedPGD:
    """í•˜ë“œì›¨ì–´ ê°€ì† PGD êµ¬í˜„"""
    
    def __init__(self):
        self.fpga_interface = FPGAInterface()
        self.custom_kernels = CustomCUDAKernels()
    
    def accelerated_gradient_computation(self, image_batch):
        """FPGA ê¸°ë°˜ ê³ ì† ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚°"""
        return self.fpga_interface.compute_gradients(image_batch)
```

#### 3. AI ìœ¤ë¦¬ ë° ê·œì œ ëŒ€ì‘
**ëª©í‘œ**: ë²•ì , ìœ¤ë¦¬ì  ìš”êµ¬ì‚¬í•­ì— ë¶€í•©í•˜ëŠ” ì‹œìŠ¤í…œ

```python
class EthicalPhotoGuard:
    """ìœ¤ë¦¬ì  ê³ ë ¤ì‚¬í•­ì´ ë°˜ì˜ëœ PhotoGuard"""
    
    def __init__(self):
        self.consent_manager = ConsentManager()
        self.audit_logger = AuditLogger()
        self.bias_monitor = BiasMonitor()
    
    def protect_with_consent(self, image, user_consent):
        """ì‚¬ìš©ì ë™ì˜ ê¸°ë°˜ ë³´í˜¸"""
        
        # 1. ë™ì˜ ê²€ì¦
        if not self.consent_manager.verify_consent(user_consent):
            raise ConsentError("Valid consent required")
        
        # 2. í¸í–¥ì„± ê²€ì‚¬
        bias_score = self.bias_monitor.check_bias(image)
        if bias_score > threshold:
            self.audit_logger.log_bias_warning(image, bias_score)
        
        # 3. ê°ì‚¬ ë¡œê¹…
        self.audit_logger.log_protection_event(
            image_hash=hash(image),
            user_id=user_consent.user_id,
            timestamp=datetime.now(),
            parameters=self.get_protection_params()
        )
        
        # 4. ë³´í˜¸ ì‹¤í–‰
        return self.apply_protection(image)

class BiasMonitor:
    """í¸í–¥ì„± ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ"""
    
    def check_bias(self, image):
        """ì´ë¯¸ì§€ì—ì„œ ì ì¬ì  í¸í–¥ì„± ê²€ì‚¬"""
        
        # 1. ì¸ì¢…/ì„±ë³„ í¸í–¥ ê²€ì‚¬
        demographic_bias = self.check_demographic_bias(image)
        
        # 2. ì—°ë ¹ í¸í–¥ ê²€ì‚¬  
        age_bias = self.check_age_bias(image)
        
        # 3. ì‚¬íšŒê²½ì œì  í¸í–¥ ê²€ì‚¬
        socioeconomic_bias = self.check_socioeconomic_bias(image)
        
        return max(demographic_bias, age_bias, socioeconomic_bias)
```

### ì„œë²„í™” ë° í™•ì¥ì„±

**ëª©í‘œ**: ì»¤ë®¤ë‹ˆí‹° ì£¼ë„ ê°œë°œ ë° í‘œì¤€í™”

```python
# í‘œì¤€í™”ëœ PhotoGuard API
class StandardPhotoGuardAPI:
    """í‘œì¤€í™”ëœ PhotoGuard ì¸í„°í˜ì´ìŠ¤"""
    
    def __init__(self, config_path='photoguard_config.yaml'):
        self.config = self.load_config(config_path)
        self.model = self.initialize_model()
    
    def protect(self, image: Image, 
                protection_level: str = 'medium',
                custom_params: dict = None) -> ProtectionResult:
        """í‘œì¤€ ë³´í˜¸ ì¸í„°í˜ì´ìŠ¤"""
        pass
    
    def evaluate(self, original: Image, 
                 protected: Image, 
                 attack_models: List[str]) -> EvaluationResult:
        """í‘œì¤€ í‰ê°€ ì¸í„°í˜ì´ìŠ¤"""
        pass

# í”ŒëŸ¬ê·¸ì¸ ì‹œìŠ¤í…œ
class PhotoGuardPlugin:
    """PhotoGuard í”ŒëŸ¬ê·¸ì¸ ê¸°ë³¸ í´ë˜ìŠ¤"""
    
    def __init__(self, name: str, version: str):
        self.name = name
        self.version = version
    
    def apply_protection(self, image: Image, params: dict) -> Image:
        raise NotImplementedError
    
    def get_default_params(self) -> dict:
        raise NotImplementedError
```


## ğŸ“š ê²°ë¡ 

### í”„ë¡œì íŠ¸ ì„±ê³¼ ìš”ì•½

ë³¸ PhotoGuard êµ¬í˜„ í”„ë¡œì íŠ¸ëŠ” MITì˜ ì´ë¡ ì  ì—°êµ¬ë¥¼ ì‹¤ìš©ì ì¸ ì›¹ ê¸°ë°˜ ì‹œìŠ¤í…œìœ¼ë¡œ ì„±ê³µì ìœ¼ë¡œ êµ¬í˜„í•œ ì¢…í•©ì ì¸ ì—°êµ¬ê°œë°œ í”„ë¡œì íŠ¸ì˜€ìŠµë‹ˆë‹¤. ì£¼ìš” ì„±ê³¼ë¥¼ ìš”ì•½í•˜ë©´ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

#### ê¸°ìˆ ì  ì„±ê³¼
1. **ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„**: ë…¼ë¬¸ì˜ PGD ê¸°ë°˜ ì ëŒ€ì  ì„­ë™ ìƒì„± ì•Œê³ ë¦¬ì¦˜ì„ êµ¬í˜„
2. **ì‹¤ì‹œê°„ ì²˜ë¦¬ ìµœì í™”**: í‰ê·  0.5-1.2ì´ˆ ë‚´ ë³´í˜¸ ì²˜ë¦¬ ì™„ë£Œë¡œ ì‹¤ìš©ì„± í™•ë³´
3. **ì •ëŸ‰ì  ê²€ì¦ ì‹œìŠ¤í…œ**: L2/Lâˆ ë…¸ë¦„, SSIM, ë³´í˜¸ íš¨ê³¼ì„± ë“± ì¢…í•©ì  í‰ê°€ ë©”íŠ¸ë¦­ ê°œë°œ
4. **ì›¹ ê¸°ë°˜ ë°ëª¨ ì‹œìŠ¤í…œ**: ì¼ë°˜ ì‚¬ìš©ìë„ ì‰½ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì§ê´€ì  ì¸í„°í˜ì´ìŠ¤ êµ¬ì¶•

#### ì„±ëŠ¥ ê²€ì¦ ê²°ê³¼
- **ë³´í˜¸ íš¨ê³¼**: í‰ê·  70-85% ë³´í˜¸ íš¨ê³¼ ë‹¬ì„± (epsilon=0.06-0.1 ê¸°ì¤€)
- **ì²˜ë¦¬ ì†ë„**: ì‹¤ì‹œê°„ ì²˜ë¦¬ ê°€ëŠ¥í•œ ìˆ˜ì¤€ìœ¼ë¡œ ìµœì í™”
- **ì•ˆì •ì„±**: ë‹¤ì–‘í•œ ì´ë¯¸ì§€ íƒ€ì…ê³¼ ê³µê²© ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ì¼ê´€ëœ ì„±ëŠ¥
- **ì‚¬ìš©ì„±**: ì›¹ ì¸í„°í˜ì´ìŠ¤ë¥¼ í†µí•œ ê°„í¸í•œ íŒŒë¼ë¯¸í„° ì¡°ì • ë° ê²°ê³¼ í™•ì¸

### í•™ìŠµëœ í•µì‹¬ ì¸ì‚¬ì´íŠ¸

#### 1. PhotoGuardì˜ ì‘ë™ ì›ë¦¬ ì´í•´
ë‹¨ìˆœíˆ ë…¸ì´ì¦ˆë¥¼ ì¶”ê°€í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, VAE ì¸ì½”ë”ì˜ ì ì¬ ê³µê°„ì„ êµë€í•˜ì—¬ ìƒì„± ëª¨ë¸ì˜ ë””ë…¸ì´ì§• ê³¼ì •ì„ ì˜ë„ì ìœ¼ë¡œ ì‹¤íŒ¨í•˜ê²Œ ë§Œë“œëŠ” ì •êµí•œ ë°©ì–´ ë©”ì»¤ë‹ˆì¦˜ì„ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤. "ìŒ©ëš±ë§ì€" ê²°ê³¼ê°€ ë‚˜ì˜¤ëŠ” ê²ƒì´ ë°”ë¡œ ì„±ê³µì ì¸ ë³´í˜¸ì˜ ì¦ê±°ì…ë‹ˆë‹¤.

#### 2. íŒŒë¼ë¯¸í„° ìµœì í™”ì˜ ì¤‘ìš”ì„±
Epsilonê³¼ iterationsì˜ ì¡°í•©ì´ ë³´í˜¸ íš¨ê³¼ì™€ ì´ë¯¸ì§€ í’ˆì§ˆ ì‚¬ì´ì˜ íŠ¸ë ˆì´ë“œì˜¤í”„ë¥¼ ê²°ì •í•˜ëŠ” í•µì‹¬ ìš”ì†Œì„ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ìƒí™©ë³„ ìµœì  ì„¤ì •ì„ ë„ì¶œí•˜ì—¬ ì‹¤ìš©ì„±ì„ í¬ê²Œ í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤.

#### 3. ì‹¤ì œ êµ¬í˜„ì˜ ë³µì¡ì„±
ë…¼ë¬¸ì˜ ì´ë¡ ì„ ì‹¤ì œ ì½”ë“œë¡œ êµ¬í˜„í•˜ëŠ” ê³¼ì •ì—ì„œ ìˆ˜ë§ì€ ì„¸ë¶€ì‚¬í•­ë“¤(ë°ì´í„° ì „ì²˜ë¦¬, ë©”ëª¨ë¦¬ ê´€ë¦¬, ì—ëŸ¬ í•¸ë“¤ë§ ë“±)ì´ ê²°ê³¼ì— í° ì˜í–¥ì„ ë¯¸ì¹œë‹¤ëŠ” ê²ƒì„ ê²½í—˜í–ˆìŠµë‹ˆë‹¤.

### ì‚¬íšŒì  ì˜ì˜ì™€ ê¸°ì—¬

#### 1. ê°œì¸ì •ë³´ ë³´í˜¸ ê¸°ìˆ ì˜ ì‹¤ìš©í™”
ë”¥í˜ì´í¬ì™€ AI ê¸°ë°˜ ì´ë¯¸ì§€ ì¡°ì‘ì´ ì‚¬íšŒì  ë¬¸ì œê°€ ë˜ê³  ìˆëŠ” í˜„ ì‹œì ì—ì„œ, ê°œì¸ì´ ìŠ¤ìŠ¤ë¡œë¥¼ ë³´í˜¸í•  ìˆ˜ ìˆëŠ” ì‹¤ìš©ì  ë„êµ¬ë¥¼ ì œê³µí–ˆìŠµë‹ˆë‹¤.

#### 2. AI ìœ¤ë¦¬ì™€ ì±…ì„ê° ìˆëŠ” AI ë°œì „
ìƒì„±í˜• AIì˜ ë¬´ë¶„ë³„í•œ ì‚¬ìš©ì— ëŒ€í•œ ê¸°ìˆ ì  ëŒ€ì‘ì±…ì„ ì œì‹œí•˜ì—¬, AI ê¸°ìˆ ì˜ ê±´ì „í•œ ë°œì „ ë°©í–¥ì„ ì œì‹œí–ˆìŠµë‹ˆë‹¤.

#### 3. ì˜¤í”ˆì†ŒìŠ¤ ìƒíƒœê³„ ê¸°ì—¬
êµ¬í˜„ ì½”ë“œì™€ ìƒì„¸í•œ ë¬¸ì„œí™”ë¥¼ í†µí•´ í›„ì† ì—°êµ¬ìë“¤ì´ í™œìš©í•  ìˆ˜ ìˆëŠ” ê¸°ë°˜ì„ ë§ˆë ¨í–ˆìŠµë‹ˆë‹¤.

### í•œê³„ì™€ í–¥í›„ ê°œì„  ë°©í–¥

#### í˜„ì¬ì˜ í•œê³„
1. **íŠ¹ì • ëª¨ë¸ì— íŠ¹í™”**: ì£¼ë¡œ Stable Diffusionì— ìµœì í™”ë¨
2. **ì „ì²˜ë¦¬ ê³µê²©ì— ì·¨ì•½**: ê°•í•œ ë¸”ëŸ¬ë§ì´ë‚˜ ì••ì¶•ìœ¼ë¡œ ì¼ë¶€ ìš°íšŒ ê°€ëŠ¥
3. **ê³„ì‚° ë¹„ìš©**: ì‹¤ì‹œê°„ ë¹„ë””ì˜¤ ì²˜ë¦¬ì—ëŠ” ì•„ì§ í•œê³„
4. **ì¼ë°˜í™” í•œê³„**: ìƒˆë¡œìš´ ìƒì„± ëª¨ë¸ì— ëŒ€í•œ íš¨ê³¼ ë¶ˆí™•ì‹¤

#### ê°œì„  ë°©í–¥
1. **ë²”ìš©ì„± í™•ëŒ€**: ë‹¤ì–‘í•œ ìƒì„± ëª¨ë¸ì— ëŒ€í•œ í†µí•© ë³´í˜¸
2. **ê²¬ê³ ì„± ê°•í™”**: ì „ì²˜ë¦¬ ê³µê²©ì— ê°•í•œ ë³´í˜¸ ë©”ì»¤ë‹ˆì¦˜
3. **íš¨ìœ¨ì„± í–¥ìƒ**: í•˜ë“œì›¨ì–´ ê°€ì† ë° ëª¨ë°”ì¼ ìµœì í™”
4. **ì ì‘ì„± ê°œì„ **: ì´ë¯¸ì§€ ë‚´ìš©ì— ë”°ë¥¸ ìë™ ìµœì í™”
