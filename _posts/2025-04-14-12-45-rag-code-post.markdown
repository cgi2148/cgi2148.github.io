---
layout: post
title:  "LCEL 고급편"
date:   2025-04-14 13:05:00 +0900
categories: [konkuk, rag-code]
--- 
# LCEL 고급편

이 문서는 `04-LCEL-Advanced.ipynb`의 내용을 기반으로, LangChain Expression Language(LCEL)의 고급 기능을 초보자도 이해할 수 있도록 설명한 복습 문서입니다.

## 1. LCEL 인터페이스 소개

### 설명
LCEL은 사용자 정의 체인을 쉽게 만들 수 있는 표준 인터페이스를 제공합니다. 이 인터페이스는 `Runnable` 프로토콜을 통해 구현되며, 다음과 같은 주요 메소드를 포함합니다:

- `stream`: 응답을 작은 조각으로 나누어 실시간으로 스트리밍합니다.
- `invoke`: 입력값으로 체인을 실행합니다.
- `batch`: 여러 입력값을 한 번에 처리합니다.

비동기 작업을 위한 메소드도 제공됩니다:
- `astream`: 비동기적으로 응답을 스트리밍합니다.
- `ainvoke`: 비동기적으로 체인을 호출합니다.
- `abatch`: 비동기적으로 여러 입력을 처리합니다.
- `astream_log`: 중간 단계와 최종 응답을 스트리밍합니다.

### 코드 예제
```python
# API KEY를 환경변수로 관리하기 위한 설정 파일
from dotenv import load_dotenv

# API KEY 정보로드
load_dotenv()

# LangSmith 추적을 설정합니다
from langchain_teddynote import logging
logging.langsmith("CH01-Basic")
```

## 2. 기본 체인 생성하기

### 설명
LCEL을 사용하면 파이프(`|`) 연산자로 간단하게 체인을 구성할 수 있습니다.

### 코드 예제
```python
from langchain_openai import ChatOpenAI
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser

# ChatOpenAI 모델 인스턴스 생성
model = ChatOpenAI()
# 프롬프트 템플릿 생성
prompt = PromptTemplate.from_template("{topic} 에 대하여 3문장으로 설명해줘.")
# 체인 생성: 프롬프트 -> 모델 -> 문자열 파서
chain = prompt | model | StrOutputParser()
```

## 3. 주요 메소드 활용하기

### stream: 실시간 출력
실시간으로 생성되는 응답을 받아볼 수 있습니다.

```python
# '멀티모달' 토픽에 대한 응답을 실시간으로 출력
for token in chain.stream({"topic": "멀티모달"}):
    print(token, end="", flush=True)
```

### invoke: 단일 호출
한 번의 호출로 완성된 응답을 받습니다.

```python
# 'ChatGPT'에 대한 응답 받기
chain.invoke({"topic": "ChatGPT"})
```

### batch: 여러 입력 일괄 처리
여러 입력을 한 번에 처리합니다.

```python
# 여러 토픽을 동시에 처리
chain.batch([
    {"topic": "ChatGPT"}, 
    {"topic": "Instagram"},
    {"topic": "멀티모달"},
    {"topic": "프로그래밍"},
    {"topic": "머신러닝"},
], config={"max_concurrency": 3})  # 최대 3개 동시 처리
```

## 4. 비동기 메소드 사용하기

### astream: 비동기 스트리밍
응답을 비동기적으로 스트리밍합니다.

```python
async for token in chain.astream({"topic": "YouTube"}):
    print(token, end="", flush=True)
```

### ainvoke: 비동기 호출
비동기로 체인을 호출합니다.

```python
my_process = chain.ainvoke({"topic": "NVDA"})
await my_process  # 완료될 때까지 대기
```

### abatch: 비동기 일괄 처리
여러 입력을 비동기적으로 처리합니다.

```python
my_abatch_process = chain.abatch([
    {"topic": "YouTube"}, 
    {"topic": "Instagram"}, 
    {"topic": "Facebook"}
])
await my_abatch_process  # 완료될 때까지 대기
```

## 5. 병렬 처리 활용하기

### 설명
`RunnableParallel`을 사용하면 여러 체인을 동시에 실행할 수 있습니다.

### 코드 예제
```python
from langchain_core.runnables import RunnableParallel

# 국가의 수도를 물어보는 체인
chain1 = (
    PromptTemplate.from_template("{country} 의 수도는 어디야?")
    | model
    | StrOutputParser()
)

# 국가의 면적을 물어보는 체인
chain2 = (
    PromptTemplate.from_template("{country} 의 면적은 얼마야?")
    | model
    | StrOutputParser()
)

# 두 체인을 병렬로 실행
combined = RunnableParallel(capital=chain1, area=chain2)

# 병렬 체인 실행
combined.invoke({"country": "대한민국"})

# 여러 국가 정보 일괄 처리
combined.batch([{"country": "대한민국"}, {"country": "미국"}])
```

---

## 핵심 요약: LCEL 고급 기능

- **멀티 체이닝**: 여러 체인을 이어붙여 복잡한 작업을 간단하게 구성
- **조건 분기**: 입력값에 따라 다른 체인을 선택 실행 (`RunnableBranch`)
- **에러 처리**: 실패 시 대체 체인을 실행 (`with_fallbacks`)
- **함수형 프로그래밍**: `map`, `pipe`, `assign` 등으로 데이터 처리
- **스트리밍**: 실시간으로 응답 생성 과정을 확인 가능
