---
layout: post
title: "Video_cutter: 얼굴 데이터 구축을 위한 영상 전처리 자동화"
date: 2025-09-30 09:20:00 +0900
categories: [newruns]
---

## 왜 Video Cutter가 필요했나
- 원본 영상은 다양한 소스에서 촬영되었고 길이와 해상도가 제각각이었습니다.  
- 얼굴 데이터셋 구축 파이프라인은 짧은 클립을 전제로 설계되어 있어, 긴 영상을 그대로 투입하면 GPU 메모리와 IO 병목이 발생했습니다.  
- 반복되는 수작업(영상 자르기, 해상도 축소, 파일명 정리)을 자동화하지 않으면, 모델 실험 속도가 현저히 떨어졌습니다.

## 가상의 디렉터리 구조
```
~/workspace/deepguard
├── pipelines/
│   └── video-cutter/
│       ├── main_cpu.py
│       ├── config_cpu.py
│       ├── logs/
│       └── temp_chunks/
└── storage/
    ├── raw-videos/            # 팀이 올린 원본 영상
    └── processed-clips/       # 150초 단위로 자른 결과
```
- `storage/raw-videos`는 폴더 트리 전체를 재귀 탐색하도록 설계해, 현장에서 복잡한 디렉터리 구조를 그대로 유지할 수 있습니다.
- 결과물은 `processed-clips/0001.mp4`, `0002.mp4`처럼 일관된 네이밍으로 저장되어 후속 파이프라인과 자동 매칭됩니다.

## 처리 파이프라인 내부 살펴보기
1. **파일 인덱싱**  
   - `os.walk`로 원본 영상을 수집하고, 이미 처리된 파일은 스킵합니다.  
   - psutil로 CPU/메모리 상태를 미리 확인해 안전하지 않은 환경에서는 경고를 띄웁니다.
2. **FFmpeg 파이프라인**  
   - `scale=iw*0.5:ih*0.5`로 해상도를 절반으로 줄이고, `-segment_time 150` 옵션으로 150초마다 분할합니다.  
   - 오디오 트랙은 제거해 파일 크기를 최소화합니다.
3. **파일명 배정 로직**  
   - 출력 폴더를 스캔해 가장 큰 번호를 찾고, 그 다음 번호부터 순차적으로 배정합니다.  
   - 경합 상황을 대비해 번호 할당과 파일 이동을 원자적으로 처리합니다.
4. **로그와 에러 복구**  
   - `logs/cpu_video_processor.log`에 성공/실패 로그를 남기고, 실패한 파일은 `temp_chunks`에 원인을 분석할 수 있도록 복사본을 남깁니다.

## 전처리 표준(데이터 가공 보고서 반영)
- 기본 해상도 축소 비율은 0.5이며, 세로 영상·저조도 환경에서는 0.6까지 조정해 디테일을 보호합니다.
- 클립 분할 길이는 150초를 표준으로 운용하며, 후속 추론 대기열과 IO 병목을 고려해 조정 가능합니다.
- 산출물은 `processed-clips/0001.mp4`와 같이 일관된 번호 규칙을 따르고, 이후 어노테이션과 1:1 매칭됩니다.

## 설정을 통해 맞춤 튜닝하기
`config_cpu.py`는 기본값을 제공하면서도 다양한 실험을 쉽게 할 수 있도록 설계했습니다.
```python
INPUT_DIR = Path("~/workspace/deepguard/storage/raw-videos")
OUTPUT_DIR = Path("~/workspace/deepguard/storage/processed-clips")
SEGMENT_DURATION = 150      # 초단위
SCALE_FACTOR = 0.5          # 해상도 축소 비율
MAX_PARALLEL_FFMEG = 2      # 동시에 실행할 ffmpeg 프로세스 수
LOG_PATH = Path("./logs/cpu_video_processor.log")
```
- 대규모 데이터를 다룰 때는 `MAX_PARALLEL_FFMEG`를 조정해 디스크 IO 병목을 피할 수 있습니다.
- 모바일 촬영본처럼 세로 영상이 많은 경우, `SCALE_FACTOR`를 0.6 정도로 높여 세부 정보 손실을 줄였습니다.

## 운영 팁 & 실패에서 배운 교훈
- **실시간 로그 추적**: 장시간 실행 시 `tail -f logs/cpu_video_processor.log`를 열어두면 실패를 즉시 파악할 수 있습니다.
- **권한 문제 대응**: 공유 NAS에 쓰기 권한이 없을 때가 있었는데, 스크립트에서 권한 오류를 감지하면 즉시 경로 수정 팁을 안내하도록 변경했습니다.
- **회복 전략**: ffmpeg가 비정상 종료하더라도 임시 파일을 남겨 두어, 실패 시점 이후부터 재시작할 수 있게 했습니다.
- **리소스 보호**: CPU 사용량이 일정 임계치를 넘으면 ffmpeg 프로세스를 일시적으로 줄여 다른 파이프라인과 공존할 수 있게 했습니다.

## 적용 사례(보고서 기준)
- 고화질 원본(약 10~20분)을 해상도 1/2로 축소하고, 150초 단위로 분할해 세그먼트를 생성했습니다.  
- 표준 네이밍(`processed-clips/0001.mp4` 등)으로 출력해 후속 어노테이션과 1:1 매칭을 보장했습니다.  
- 최종 산출 기준: MP4 3,000건(세그먼트)과 동일 파일명 JSON 3,000건으로 구성되며, 파이프라인 전 단계와 연동됩니다.  
- 전처리 단계에서 손상/비정상 파일은 자동 제외하고, 구조 오류율 0.1% 미만 목표 달성에 기여했습니다.

